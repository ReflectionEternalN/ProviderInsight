import streamlit as st
import pandas as pd
import plotly.express as px
import os
from io import BytesIO

# =========================
# é¡µé¢é…ç½®ä¸æ ·å¼ï¼ˆå­—å·ä¼˜åŒ– + å›¾æ ‡å‹å¥½ï¼‰
# =========================
st.set_page_config(page_title="èµ„è®¯å¹³å°æ•°æ®åˆ†æ", layout="wide")

# å…¨å±€æ ·å¼ï¼šæ§åˆ¶æ ‡é¢˜å­—å·ï¼ˆé€‚å½“å¢å¤§ï¼‰ï¼Œå¹¶æä¾›è‡ªå®šä¹‰ç±»
st.markdown("""
<style>
/* å…¨å±€æ ‡é¢˜åŸºç¡€ï¼ˆé€‚ä¸­ï¼‰ */
h1 { font-size: 1.25rem !important; }
h2 { font-size: 1.15rem !important; }
h3 { font-size: 1.05rem !important; }

/* åŠŸèƒ½é¡µé¡¶ç«¯æ ‡é¢˜ï¼ˆå¢å¤§çº¦ä¸€åŠï¼Œçªå‡ºæ¯é¡µä¸»æ ‡é¢˜ï¼‰ */
.page-title {
    font-size: 1.60rem !important; /* åŸåŸºç¡€ä¸Šå¢å¤§çº¦ä¸€åŠ */
    font-weight: 700;
    margin: 0.25rem 0 0.75rem 0;
}

/* åŠŸèƒ½æè¿°ï¼ˆä¸åŠŸèƒ½é¡µé¡¶ç«¯æ ‡é¢˜åŒå­—å·ï¼Œç®€æ´è¯´æ˜å½“å‰é¡µï¼‰ */
.page-subtitle {
    font-size: 1.60rem !important; /* ä¸ page-title åŒå­—å· */
    font-weight: 600;
    color: #444;
    margin: 0 0 0.75rem 0;
}

/* æŠ¥è­¦åŒºåŸŸçš„æ ·å¼é€‚å½“ç´§å‡‘ */
.alert-exclam { color: #d00000; font-weight: 800; font-size: 16px; margin-right: 6px; }
.alert-line { font-size: 14px; line-height: 1.6; }
.alert-box { padding: 8px 10px; background-color: #fff5f5; border-left: 4px solid #d00000; border-radius: 6px; margin-bottom: 12px; }

/* å°æ ‡é¢˜ï¼ˆç»„åˆ«ï¼‰ */
.section-title {
    font-size: 1.05rem !important;
    font-weight: 600;
    margin: 0.5rem 0 0.5rem 0;
}
</style>
""", unsafe_allow_html=True)

# é¡¶éƒ¨ä¸»æ ‡é¢˜ï¼ˆé€‚ä¸­ï¼‰
st.title("ğŸ“Š èµ„è®¯å¹³å°æ–‡ç« å®¡æ ¸æ•°æ®åˆ†æ")

# =========================
# èœå•ï¼ˆå››ä¸ªé¡¶çº§åŠŸèƒ½ï¼‰
# =========================
menu = st.sidebar.radio("é€‰æ‹©åŠŸèƒ½", [
    "åŠŸèƒ½ 1ï¼šå•æ—¥åˆ†æ",
    "åŠŸèƒ½ 2ï¼šä»…å·¥ä½œæ—¥",
    "åŠŸèƒ½ 3ï¼šä»…å‘¨æœ«",
    "åŠŸèƒ½ 4ï¼šå…¨éƒ¨æ•°æ®"
])

# =========================
# ä¸Šä¼ æ–‡ä»¶
# =========================
st.sidebar.markdown("ğŸ—‚ï¸ æ–‡ä»¶ä¸Šä¼ ")
provider_file = st.sidebar.file_uploader("ä¸Šä¼  Provider ID & Name", type=["xlsx"])
import_files = st.sidebar.file_uploader("ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶", type=["xlsx"], accept_multiple_files=True)
holidays_file = st.sidebar.file_uploader("ä¸Šä¼ èŠ‚å‡æ—¥", type=["csv"])

# =========================
# å…¨å±€å‚æ•°ï¼ˆæŠ¥è­¦é˜ˆå€¼ï¼‰
# =========================
st.sidebar.markdown("âš™ï¸ å‚æ•°è®¾ç½®")
alert_threshold_pct = st.sidebar.slider("æŠ¥è­¦é˜ˆå€¼ï¼ˆ%ï¼‰", min_value=10, max_value=90, value=50, step=5)

# =========================
# å·¥å…·å‡½æ•°
# =========================
def export_excel(df, filename):
    output = BytesIO()
    writer = None
    for eng in ("openpyxl", "xlsxwriter"):
        try:
            writer = pd.ExcelWriter(output, engine=eng)
            break
        except Exception:
            writer = None
    if writer is None:
        st.error("ç¼ºå°‘ Excel å†™å…¥å¼•æ“ï¼Œè¯·å®‰è£… openpyxl æˆ– XlsxWriter")
        st.stop()
    with writer:
        df.to_excel(writer, index=False, sheet_name='Sheet1')
    st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœ", output.getvalue(), file_name=filename,
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

def normalize_columns(df):
    df.columns = [col.strip().lower() for col in df.columns]
    return df

def parse_date_series(s):
    return pd.to_datetime(s, errors='coerce').dt.date

def load_holidays_set(uploaded_csv) -> set:
    if uploaded_csv is None:
        return set()
    try:
        df = pd.read_csv(uploaded_csv)
        df = normalize_columns(df)
        if "date" not in df.columns:
            st.error("èŠ‚å‡æ—¥æ–‡ä»¶éœ€åŒ…å«åˆ—ï¼šdate")
            return set()
        df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.date
        df = df.dropna(subset=["date"]).reset_index(drop=True)
        return set(df["date"].tolist())
    except Exception as e:
        st.error(f"è¯»å–èŠ‚å‡æ—¥æ–‡ä»¶å¤±è´¥ï¼š{e}")
        return set()

def anomaly_alerts_block(df_daily: pd.DataFrame, title_latest_day: str, filename_prefix: str, threshold_pct: float):
    if df_daily.empty or df_daily["date"].isna().all():
        st.warning("æ— å¯ç”¨æ—¥æœŸæ•°æ®")
        return

    latest_date = df_daily["date"].max()
    latest_df = df_daily[df_daily["date"] == latest_date].copy()
    history_df = df_daily[df_daily["date"] < latest_date].copy()

    # æŠ¥è­¦åŒºåŸŸæ ·å¼å·²åœ¨å…¨å±€ CSS å®šä¹‰
    if history_df.empty:
        st.markdown(
            f"<div class='alert-box'>ä»…æœ‰{title_latest_day} {pd.to_datetime(latest_date).strftime('%Y/%m/%d')}ï¼Œæ— å†å²å¯¹æ¯”</div>",
            unsafe_allow_html=True
        )
        return

    hist_mean = (
        history_df.groupby(["providerid", "provider_label"], dropna=False)["importcount"]
        .mean().reset_index().rename(columns={"importcount": "hist_avg"})
    )

    compare_df = pd.merge(
        latest_df[["providerid", "provider_label", "date", "importcount"]],
        hist_mean, on=["providerid", "provider_label"], how="left"
    )
    compare_df = compare_df[compare_df["hist_avg"] > 500].copy()

    compare_df["change_ratio"] = (compare_df["importcount"] - compare_df["hist_avg"]) / compare_df["hist_avg"]
    compare_df["direction"] = compare_df["change_ratio"].apply(lambda x: "ä¸Šå‡" if x >= 0 else "é™ä½")
    compare_df["change_pct"] = (compare_df["change_ratio"] * 100).round(2)

    threshold_ratio = float(threshold_pct) / 100.0
    alerts_df = compare_df[compare_df["change_ratio"].abs() >= threshold_ratio].copy()

    if alerts_df.empty:
        st.markdown(
            f"<div class='alert-box'>âœ… {title_latest_day} {pd.to_datetime(latest_date).strftime('%Y/%m/%d')} æœªå‘ç°å¼‚å¸¸</div>",
            unsafe_allow_html=True
        )
    else:
        st.markdown(
            f"<div class='alert-box'><b>ğŸš¨ å¼‚å¸¸æŠ¥è­¦ï¼ˆé˜ˆå€¼ {threshold_pct}%ï¼‰</b><br/>",
            unsafe_allow_html=True
        )
        for _, row in alerts_df.sort_values(by="change_ratio", key=lambda s: s.abs(), ascending=False).iterrows():
            date_str = pd.to_datetime(row["date"]).strftime("%Y/%m/%d")
            msg = f"<span class='alert-exclam'>ï¼</span><span class='alert-line'>{row['provider_label']} åœ¨ {date_str} çš„æ±‡å…¥é‡å¼‚å¸¸{row['direction']}</span>"
            st.markdown(msg, unsafe_allow_html=True)
        st.markdown("</div>", unsafe_allow_html=True)

        show_cols = ["providerid", "provider_label", "date", "importcount", "hist_avg", "change_pct", "direction"]
        pretty_df = alerts_df[show_cols].copy()
        pretty_df = pretty_df.rename(columns={
            "providerid": "ProviderId",
            "provider_label": "æä¾›æ–¹",
            "date": "æ—¥æœŸ",
            "importcount": "æœ€æ–°æ—¥æ±‡å…¥é‡",
            "hist_avg": "è¿‡å¾€å‡å€¼",
            "change_pct": "å˜åŒ–ç™¾åˆ†æ¯”",
            "direction": "æ–¹å‘"
        })
        pretty_df["æ—¥æœŸ"] = pd.to_datetime(pretty_df["æ—¥æœŸ"]).dt.strftime("%Y/%m/%d")
        with st.expander("æŸ¥çœ‹å¼‚å¸¸æ˜ç»†", expanded=False):
            st.dataframe(pretty_df, use_container_width=True)
            export_excel(pretty_df, f"{filename_prefix}_å¼‚å¸¸_{pd.to_datetime(latest_date).strftime('%Y%m%d')}.xlsx")

def prepare_import_data(import_files, provider_map):
    import_data = pd.DataFrame()
    if import_files:
        for file in import_files:
            df = pd.read_excel(file)
            df = normalize_columns(df)
            date_str = os.path.splitext(file.name)[0]
            df["date"] = date_str
            import_data = pd.concat([import_data, df], ignore_index=True)

    if import_data.empty:
        return import_data

    if "providerid" not in import_data.columns or "importcount" not in import_data.columns:
        st.error("æ±‡å…¥é‡æ–‡ä»¶éœ€åŒ…å«åˆ—ï¼šProviderId ä¸ ImportCount")
        st.stop()

    if not provider_map.empty:
        import_data = import_data.merge(provider_map, on="providerid", how="left")

    import_data["providerid_str"] = import_data["providerid"].astype(str)
    if "providername" in import_data.columns:
        import_data["provider_label"] = import_data["providername"].where(import_data["providername"].notna(),
                                                                        import_data["providerid_str"])
    else:
        import_data["provider_label"] = import_data["providerid_str"]

    import_data["date_parsed"] = parse_date_series(import_data["date"])
    if import_data["date_parsed"].isna().any():
        st.warning("å‘ç°æ— æ•ˆæ—¥æœŸè®°å½•ï¼Œå·²å¿½ç•¥")
        import_data = import_data[~import_data["date_parsed"].isna()].copy()

    return import_data

# =========================
# Provider æ˜ å°„
# =========================
provider_map = pd.DataFrame()
if provider_file:
    try:
        provider_map = pd.read_excel(provider_file)
        provider_map = normalize_columns(provider_map)
        if "providername" not in provider_map.columns or "providerid" not in provider_map.columns:
            st.error("Provider æ˜ å°„éœ€åŒ…å«ï¼šProviderName ä¸ ProviderId")
            st.stop()
        provider_map = provider_map.drop_duplicates(subset=["providerid"]).reset_index(drop=True)
    except Exception as e:
        st.error(f"è¯»å– Provider æ˜ å°„å¤±è´¥ï¼š{e}")
        st.stop()

# =========================
# æ±‡å…¥é‡ä¸èŠ‚å‡æ—¥
# =========================
import_data = prepare_import_data(import_files, provider_map)
holidays_set = load_holidays_set(holidays_file)

# =========================
# åŠŸèƒ½ 1ï¼šå•æ—¥åˆ†æ
# =========================
if menu == "åŠŸèƒ½ 1ï¼šå•æ—¥åˆ†æ":
    st.markdown("<div class='page-title'>ğŸ—“ï¸ğŸ“Š å•æ—¥åˆ†æ</div>", unsafe_allow_html=True)
    st.markdown("<div class='page-subtitle'>å•æ—¥æ•°æ®æ€»è§ˆ</div>", unsafe_allow_html=True)

    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        dates = sorted(import_data["date_parsed"].dropna().unique())
        if not dates:
            st.warning("æ— æœ‰æ•ˆæ—¥æœŸ")
        else:
            date_strs = [pd.to_datetime(d).strftime("%Y-%m-%d") for d in dates]
            selected_date_str = st.selectbox("é€‰æ‹©æ—¥æœŸ", date_strs)
            selected_date = pd.to_datetime(selected_date_str).date()

            day_data = import_data[import_data["date_parsed"] == selected_date]
            provider_counts = (day_data.groupby("provider_label", dropna=False)["importcount"]
                               .sum().reset_index().sort_values(by="importcount", ascending=False))
            provider_counts = provider_counts.rename(columns={"provider_label": "æä¾›æ–¹", "importcount": "æ±‡å…¥æ•°é‡"})

            st.dataframe(provider_counts, use_container_width=True)
            fig = px.bar(provider_counts, x="æä¾›æ–¹", y="æ±‡å…¥æ•°é‡", title=f"{selected_date_str} æ±‡å…¥æ•°é‡")
            st.plotly_chart(fig, use_container_width=True)

            export_excel(provider_counts, f"å•æ—¥_æ±‡å…¥_{selected_date_str}.xlsx")

# =========================
# åŠŸèƒ½ 2ï¼šä»…å·¥ä½œæ—¥
# =========================
elif menu == "åŠŸèƒ½ 2ï¼šä»…å·¥ä½œæ—¥":
    st.markdown("<div class='page-title'>ğŸ§‘â€ğŸ’¼ğŸ“ˆ ä»…å·¥ä½œæ—¥</div>", unsafe_allow_html=True)
    st.markdown("<div class='page-subtitle'>ä»…ç»Ÿè®¡å‘¨ä¸€è‡³å‘¨äº”</div>", unsafe_allow_html=True)

    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        all_providers = sorted(import_data["provider_label"].dropna().unique().tolist())
        whitelist = st.sidebar.multiselect("æä¾›æ–¹ç­›é€‰", options=all_providers, default=[])

        df = import_data.copy()
        if whitelist:
            df = df[df["provider_label"].isin(whitelist)].copy()

        df["weekday"] = pd.to_datetime(df["date_parsed"]).dt.weekday
        df = df[df["weekday"] < 5].copy()

        use_holidays = st.checkbox("æ’é™¤èŠ‚å‡æ—¥", value=True, key="workdays_holiday_toggle")
        if use_holidays:
            if len(holidays_set) > 0:
                df = df[~df["date_parsed"].isin(holidays_set)].copy()
            else:
                st.info("æœªæä¾›èŠ‚å‡æ—¥æ–‡ä»¶")

        if df.empty:
            st.warning("æ— æ•°æ®")
        else:
            daily_import = (df.groupby(["providerid", "provider_label", "date_parsed"], dropna=False)["importcount"]
                            .sum().reset_index().rename(columns={"date_parsed": "date"}))
            anomaly_alerts_block(daily_import, "æœ€æ–°å·¥ä½œæ—¥", "ä»…å·¥ä½œæ—¥", alert_threshold_pct)

            provider_total = df.groupby("provider_label", dropna=False)["importcount"].sum().sort_values(ascending=False)
            providers_sorted = provider_total.index.tolist()
            group_size = 10
            provider_groups = [providers_sorted[i:i+group_size] for i in range(0, len(providers_sorted), group_size)]

            trend_data = (df.groupby(["date_parsed", "provider_label"], dropna=False)["importcount"]
                          .sum().reset_index().rename(columns={"date_parsed": "date"}).sort_values(by="date"))

            all_group_data = []
            for idx, group in enumerate(provider_groups, start=1):
                st.markdown(f"<div class='section-title'>ğŸ“ˆ ç¬¬ {idx} ç»„</div>", unsafe_allow_html=True)
                group_data = trend_data[trend_data["provider_label"].isin(group)]
                all_group_data.append(group_data)
                fig = px.line(group_data, x="date", y="importcount", color="provider_label",
                              labels={"provider_label": "æä¾›æ–¹", "importcount": "æ±‡å…¥æ•°é‡", "date": "æ—¥æœŸ"},
                              title="")
                st.plotly_chart(fig, use_container_width=True)
            if all_group_data:
                export_excel(pd.concat(all_group_data), "è¶‹åŠ¿_ä»…å·¥ä½œæ—¥.xlsx")

# =========================
# åŠŸèƒ½ 3ï¼šä»…å‘¨æœ«
# =========================
elif menu == "åŠŸèƒ½ 3ï¼šä»…å‘¨æœ«":
    st.markdown("<div class='page-title'>ğŸ›ŒğŸ“ˆ ä»…å‘¨æœ«</div>", unsafe_allow_html=True)
    st.markdown("<div class='page-subtitle'>ä»…ç»Ÿè®¡å‘¨å…­ä¸å‘¨æ—¥</div>", unsafe_allow_html=True)

    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        all_providers = sorted(import_data["provider_label"].dropna().unique().tolist())
        whitelist = st.sidebar.multiselect("æä¾›æ–¹ç­›é€‰", options=all_providers, default=[], key="wl_weekends")

        df = import_data.copy()
        if whitelist:
            df = df[df["provider_label"].isin(whitelist)].copy()

        df["weekday"] = pd.to_datetime(df["date_parsed"]).dt.weekday
        df = df[df["weekday"] >= 5].copy()

        if df.empty:
            st.warning("æ— æ•°æ®")
        else:
            daily_import = (df.groupby(["providerid", "provider_label", "date_parsed"], dropna=False)["importcount"]
                            .sum().reset_index().rename(columns={"date_parsed": "date"}))
            anomaly_alerts_block(daily_import, "æœ€æ–°å‘¨æœ«æ—¥", "ä»…å‘¨æœ«", alert_threshold_pct)

            provider_total = df.groupby("provider_label", dropna=False)["importcount"].sum().sort_values(ascending=False)
            providers_sorted = provider_total.index.tolist()
            group_size = 10
            provider_groups = [providers_sorted[i:i+group_size] for i in range(0, len(providers_sorted), group_size)]

            trend_data = (df.groupby(["date_parsed", "provider_label"], dropna=False)["importcount"]
                          .sum().reset_index().rename(columns={"date_parsed": "date"}).sort_values(by="date"))

            all_group_data = []
            for idx, group in enumerate(provider_groups, start=1):
                st.markdown(f"<div class='section-title'>ğŸ“ˆ ç¬¬ {idx} ç»„</div>", unsafe_allow_html=True)
                group_data = trend_data[trend_data["provider_label"].isin(group)]
                all_group_data.append(group_data)
                fig = px.line(group_data, x="date", y="importcount", color="provider_label",
                              labels={"provider_label": "æä¾›æ–¹", "importcount": "æ±‡å…¥æ•°é‡", "date": "æ—¥æœŸ"},
                              title="")
                st.plotly_chart(fig, use_container_width=True)
            if all_group_data:
                export_excel(pd.concat(all_group_data), "è¶‹åŠ¿_ä»…å‘¨æœ«.xlsx")

# =========================
# åŠŸèƒ½ 4ï¼šå…¨éƒ¨æ•°æ®
# =========================
elif menu == "åŠŸèƒ½ 4ï¼šå…¨éƒ¨æ•°æ®":
    st.markdown("<div class='page-title'>ğŸ“šğŸ“ˆ å…¨éƒ¨æ•°æ®</div>", unsafe_allow_html=True)
    st.markdown("<div class='page-subtitle'>ç»Ÿè®¡å…¨éƒ¨ä¸Šä¼ æ•°æ®</div>", unsafe_allow_html=True)

    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        all_providers = sorted(import_data["provider_label"].dropna().unique().tolist())
        whitelist = st.sidebar.multiselect("æä¾›æ–¹ç­›é€‰", options=all_providers, default=[], key="wl_all")

        df = import_data.copy()
        if whitelist:
            df = df[df["provider_label"].isin(whitelist)].copy()

        if df.empty:
            st.warning("æ— æ•°æ®")
        else:
            daily_import = (df.groupby(["providerid", "provider_label", "date_parsed"], dropna=False)["importcount"]
                            .sum().reset_index().rename(columns={"date_parsed": "date"}))
            anomaly_alerts_block(daily_import, "æœ€æ–°ä¸€å¤©", "å…¨éƒ¨æ•°æ®", alert_threshold_pct)

            provider_total = df.groupby("provider_label", dropna=False)["importcount"].sum().sort_values(ascending=False)
            providers_sorted = provider_total.index.tolist()
            group_size = 10
            provider_groups = [providers_sorted[i:i+group_size] for i in range(0, len(providers_sorted), group_size)]

            trend_data = (df.groupby(["date_parsed", "provider_label"], dropna=False)["importcount"]
                          .sum().reset_index().rename(columns={"date_parsed": "date"}).sort_values(by="date"))

            all_group_data = []
            for idx, group in enumerate(provider_groups, start=1):
                st.markdown(f"<div class='section-title'>ğŸ“ˆ ç¬¬ {idx} ç»„</div>", unsafe_allow_html=True)
                group_data = trend_data[trend_data["provider_label"].isin(group)]
                all_group_data.append(group_data)
                fig = px.line(group_data, x="date", y="importcount", color="provider_label",
                              labels={"provider_label": "æä¾›æ–¹", "importcount": "æ±‡å…¥æ•°é‡", "date": "æ—¥æœŸ"},
                              title="")
                st.plotly_chart(fig, use_container_width=True)
            if all_group_data:
                export_excel(pd.concat(all_group_data), "è¶‹åŠ¿_å…¨éƒ¨æ•°æ®.xlsx")
