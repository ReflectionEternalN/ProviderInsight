import streamlit as st
import pandas as pd
import plotly.express as px
import os
from io import BytesIO

# =========================
# é¡µé¢é…ç½®
# =========================
st.set_page_config(page_title="èµ„è®¯å¹³å°æ•°æ®åˆ†æ", layout="wide")
st.title("ğŸ“Š èµ„è®¯å¹³å°æ–‡ç« å®¡æ ¸æ•°æ®åˆ†æ")

# =========================
# Sidebar èœå•
# =========================
menu = st.sidebar.radio("é€‰æ‹©åŠŸèƒ½", [
    "åŠŸèƒ½ 1ï¼šå•æ—¥ Provider æ±‡å…¥æ•°é‡åˆ†æ",
    "åŠŸèƒ½ 2ï¼šå¤šæ—¥è¶‹åŠ¿åˆ†æï¼ˆåˆ†ç»„æ˜¾ç¤ºï¼‰"
])

# =========================
# ä¸Šä¼ æ–‡ä»¶
# =========================
st.sidebar.markdown("### ä¸Šä¼ æ–‡ä»¶")
provider_file = st.sidebar.file_uploader("ä¸Šä¼  Provider æ˜ å°„ï¼ˆxlsxï¼Œéœ€å« ProviderName å’Œ ProviderIdï¼‰", type=["xlsx"])
import_files = st.sidebar.file_uploader("ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶ï¼ˆxlsxï¼Œå¯å¤šé€‰ï¼‰", type=["xlsx"], accept_multiple_files=True)
holidays_file = st.sidebar.file_uploader("ä¸Šä¼ èŠ‚å‡æ—¥æ–‡ä»¶ï¼ˆCSVï¼Œéœ€å«åˆ—ï¼šdateï¼Œå¯é€‰ holiday_nameï¼‰", type=["csv"])

# =========================
# åŠŸèƒ½ 2 å‚æ•°ï¼ˆç™½åå• + æŠ¥è­¦é˜ˆå€¼ï¼‰
# =========================
st.sidebar.markdown("### åŠŸèƒ½ 2 å‚æ•°è®¾ç½®")
alert_threshold_pct = st.sidebar.slider("å¼‚å¸¸æŠ¥è­¦é˜ˆå€¼ï¼ˆ%ï¼‰", min_value=10, max_value=90, value=50, step=5,
                                        help="å½“æœ€æ–°æ—¥ä¸å†å²å‡å€¼çš„ç›¸å¯¹å˜åŒ–å¹…åº¦ â‰¥ é˜ˆå€¼æ—¶è§¦å‘æŠ¥è­¦ã€‚é»˜è®¤ 50%")
# ç™½åå•åœ¨æ•°æ®åŠ è½½ååŠ¨æ€æä¾›ï¼ˆè§åŠŸèƒ½ 2 ä»£ç å—ï¼‰

# =========================
# å·¥å…·å‡½æ•°
# =========================
def export_excel(df, filename):
    """Excel å¯¼å‡ºï¼ˆè‡ªåŠ¨é€‰æ‹© openpyxl / xlsxwriter å¼•æ“ï¼‰"""
    output = BytesIO()
    writer = None
    for eng in ("openpyxl", "xlsxwriter"):
        try:
            writer = pd.ExcelWriter(output, engine=eng)
            break
        except Exception:
            writer = None
    if writer is None:
        st.error("æœªæ‰¾åˆ°å¯ç”¨çš„ Excel å†™å…¥å¼•æ“ï¼Œè¯·å®‰è£… openpyxl æˆ– XlsxWriter")
        st.stop()
    with writer:
        df.to_excel(writer, index=False, sheet_name='Sheet1')
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½åˆ†æç»“æœ",
        data=output.getvalue(),
        file_name=filename,
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

def normalize_columns(df):
    df.columns = [col.strip().lower() for col in df.columns]
    return df

def parse_date_series(s):
    """
    å°†å­—ç¬¦ä¸²è§£æä¸ºæ—¥æœŸï¼ˆæ”¯æŒ YYYY-MM-DD / YYYYMMDD ç­‰ï¼‰ï¼Œå¤±è´¥è¿”å› NaTã€‚
    é€šå¸¸ç”¨æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ä½œä¸ºæ—¥æœŸæ¥æºã€‚
    """
    dt = pd.to_datetime(s, errors='coerce')
    return dt.dt.date

def load_holidays_set(uploaded_csv) -> set:
    """
    ä»ä¸Šä¼ çš„ holidays.csv è¯»å–èŠ‚å‡æ—¥é›†åˆï¼ˆé€æ—¥å£å¾„ï¼‰ã€‚
    éœ€è¦è‡³å°‘åŒ…å« date åˆ—ï¼›holiday_name å¯é€‰ã€‚
    è¿”å›ï¼šset[date]
    """
    if uploaded_csv is None:
        return set()
    try:
        df = pd.read_csv(uploaded_csv)
        df = normalize_columns(df)
        if "date" not in df.columns:
            st.error("holidays.csv å¿…é¡»åŒ…å«åˆ—ï¼šdateï¼ˆæ ¼å¼å»ºè®® YYYY-MM-DDï¼‰")
            return set()
        df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.date
        df = df.dropna(subset=["date"]).reset_index(drop=True)
        return set(df["date"].tolist())
    except Exception as e:
        st.error(f"è¯»å–èŠ‚å‡æ—¥æ–‡ä»¶å¤±è´¥ï¼š{e}")
        return set()

def anomaly_alerts_block(df_daily: pd.DataFrame, title_latest_day: str, anomaly_filename_prefix: str, threshold_pct: float):
    """
    é¡¶éƒ¨å¼‚å¸¸æŠ¥è­¦å—ï¼š
    - df_dailyï¼šæŒ‰ providerid / provider_label / dateï¼ˆæ—¥æœŸï¼‰æ±‡æ€»åçš„ DataFrameï¼ˆåˆ—ï¼šproviderid, provider_label, date, importcountï¼‰
    - title_latest_dayï¼šç”¨äºå±•ç¤ºçš„â€œæœ€æ–°æ—¥â€æ ‡é¢˜ï¼ˆå¦‚ 'æœ€æ–°å·¥ä½œæ—¥' / 'æœ€æ–°ä¸€å¤©'ï¼‰
    - anomaly_filename_prefixï¼šå¯¼å‡ºæ–‡ä»¶å‰ç¼€ï¼ˆå¦‚ 'WorkdaysOnly' / 'AllIncluded'ï¼‰
    - threshold_pctï¼šæŠ¥è­¦é˜ˆå€¼ï¼ˆç™¾åˆ†æ¯”ï¼‰ï¼Œä¾‹å¦‚ 50 è¡¨ç¤º 50%
    """
    if df_daily.empty or df_daily["date"].isna().all():
        st.warning("æ²¡æœ‰æœ‰æ•ˆçš„æ—¥æœŸæ•°æ®ï¼Œæ— æ³•è®¡ç®—å¼‚å¸¸ã€‚")
        return

    latest_date = df_daily["date"].max()
    latest_df = df_daily[df_daily["date"] == latest_date].copy()
    history_df = df_daily[df_daily["date"] < latest_date].copy()

    st.markdown("""
        <style>
        .alert-exclam { color: #d00000; font-weight: 800; font-size: 18px; margin-right: 6px; }
        .alert-line { font-size: 16px; line-height: 1.6; }
        .alert-box { padding: 10px 12px; background-color: #fff5f5; border-left: 4px solid #d00000; border-radius: 6px; margin-bottom: 16px; }
        </style>
    """, unsafe_allow_html=True)

    if history_df.empty:
        st.markdown(
            f"<div class='alert-box'>ä»…æœ‰{title_latest_day}ï¼ˆ{pd.to_datetime(latest_date).strftime('%Y/%m/%d')}ï¼‰ï¼Œç¼ºå°‘è¿‡å¾€æ•°æ®ç”¨äºå¯¹æ¯”ï¼Œæš‚æ— æ³•æŠ¥è­¦ã€‚</div>",
            unsafe_allow_html=True
        )
        return

    # å†å²å‡å€¼ï¼ˆä¸å«æœ€æ–°æ—¥ï¼‰
    hist_mean = (
        history_df.groupby(["providerid", "provider_label"], dropna=False)["importcount"]
        .mean()
        .reset_index()
        .rename(columns={"importcount": "hist_avg"})
    )

    # åˆå¹¶æœ€æ–°æ—¥æ•°æ®
    compare_df = pd.merge(
        latest_df[["providerid", "provider_label", "date", "importcount"]],
        hist_mean,
        on=["providerid", "provider_label"],
        how="left"
    )

    # ä»…ä¿ç•™å†å²å‡å€¼ > 500 çš„ Provider
    compare_df = compare_df[compare_df["hist_avg"] > 500].copy()

    # å˜åŒ–æ¯”ä¾‹ä¸æ–¹å‘
    compare_df["change_ratio"] = (compare_df["importcount"] - compare_df["hist_avg"]) / compare_df["hist_avg"]
    compare_df["direction"] = compare_df["change_ratio"].apply(lambda x: "ä¸Šå‡" if x >= 0 else "é™ä½")
    compare_df["change_pct"] = (compare_df["change_ratio"] * 100).round(2)

    # é˜ˆå€¼ï¼ˆç™¾åˆ†æ¯” â†’ æ¯”ä¾‹ï¼‰
    threshold_ratio = float(threshold_pct) / 100.0
    alerts_df = compare_df[compare_df["change_ratio"].abs() >= threshold_ratio].copy()

    if alerts_df.empty:
        st.markdown(
            f"<div class='alert-box'>âœ… {title_latest_day}ï¼ˆ{pd.to_datetime(latest_date).strftime('%Y/%m/%d')}ï¼‰æœªå‘ç°å¼‚å¸¸æ³¢åŠ¨ï¼ˆæ»¡è¶³æ¡ä»¶çš„ Providerï¼‰ã€‚</div>",
            unsafe_allow_html=True
        )
    else:
        st.markdown(
            f"<div class='alert-box'><b>ğŸš© å¼‚å¸¸æŠ¥è­¦ï¼ˆ{title_latest_day}ï¼š{pd.to_datetime(latest_date).strftime('%Y/%m/%d')}ï¼Œé˜ˆå€¼ï¼š{threshold_pct}%ï¼‰</b><br/>",
            unsafe_allow_html=True
        )
        for _, row in alerts_df.sort_values(by="change_ratio", key=lambda s: s.abs(), ascending=False).iterrows():
            date_str = pd.to_datetime(row["date"]).strftime("%Y/%m/%d")
            provider = row["provider_label"]
            msg = f"<span class='alert-exclam'>ï¼</span><span class='alert-line'>{provider} åœ¨ {date_str} çš„æ±‡å…¥é‡å¼‚å¸¸{row['direction']}</span>"
            st.markdown(msg, unsafe_allow_html=True)
        st.markdown("</div>", unsafe_allow_html=True)

        # å¼‚å¸¸æ˜ç»†å¯¼å‡º
        show_cols = ["providerid", "provider_label", "date", "importcount", "hist_avg", "change_pct", "direction"]
        pretty_df = alerts_df[show_cols].copy()
        pretty_df = pretty_df.rename(columns={
            "providerid": "ProviderId",
            "provider_label": "Provider",
            "date": "æœ€æ–°æ—¥æœŸ",
            "importcount": "æœ€æ–°æ—¥æ±‡å…¥é‡",
            "hist_avg": "è¿‡å¾€æ—¥å‡å€¼",
            "change_pct": "å˜åŒ–ç™¾åˆ†æ¯”(%)",
            "direction": "æ–¹å‘"
        })
        pretty_df["æœ€æ–°æ—¥æœŸ"] = pd.to_datetime(pretty_df["æœ€æ–°æ—¥æœŸ"]).dt.strftime("%Y/%m/%d")
        with st.expander("æŸ¥çœ‹å¼‚å¸¸æ˜ç»†ï¼ˆå«ä¸‹è½½ï¼‰", expanded=False):
            st.dataframe(pretty_df, use_container_width=True)
            export_excel(pretty_df, f"Import_Anomaly_{anomaly_filename_prefix}_{pd.to_datetime(latest_date).strftime('%Y%m%d')}.xlsx")

def prepare_import_data(import_files, provider_map):
    """
    è¯»å–ä¸Šä¼ çš„ import xlsx æ–‡ä»¶ï¼Œåˆå¹¶ provider_mapï¼Œè§£ææ—¥æœŸï¼Œæ„é€ å±•ç¤ºæ ‡ç­¾ provider_labelã€‚
    è¿”å›ï¼šimport_dataï¼ˆå«åˆ—ï¼šprovideridã€providernameï¼ˆå¯ç©ºï¼‰ã€provider_labelã€importcountã€date_parsedï¼‰
    """
    import_data = pd.DataFrame()
    if import_files:
        for file in import_files:
            df = pd.read_excel(file)
            df = normalize_columns(df)
            date_str = os.path.splitext(file.name)[0]  # ç”¨æ–‡ä»¶åä½œä¸ºæ—¥æœŸæ¥æº
            df["date"] = date_str
            import_data = pd.concat([import_data, df], ignore_index=True)

    if import_data.empty:
        return import_data

    # åŸºç¡€åˆ—æ ¡éªŒ
    if "providerid" not in import_data.columns or "importcount" not in import_data.columns:
        st.error("æ±‡å…¥é‡æ–‡ä»¶å¿…é¡»åŒ…å«åˆ—ï¼šProviderId å’Œ ImportCount")
        st.stop()

    # åˆå¹¶ Provider åç§°
    if not provider_map.empty:
        import_data = import_data.merge(provider_map, on="providerid", how="left")

    # æ„é€ å±•ç¤ºæ ‡ç­¾ï¼ˆä¼˜å…ˆ providernameï¼Œå¦åˆ™ç”¨ provideridï¼‰
    # providerid å¯èƒ½ä¸ºæ•°å€¼ï¼Œéœ€è½¬ä¸ºå­—ç¬¦ä¸²
    import_data["providerid_str"] = import_data["providerid"].astype(str)
    if "providername" in import_data.columns:
        import_data["provider_label"] = import_data["providername"].where(import_data["providername"].notna(), import_data["providerid_str"])
    else:
        import_data["provider_label"] = import_data["providerid_str"]

    # è§£ææ—¥æœŸ
    import_data["date_parsed"] = parse_date_series(import_data["date"])
    if import_data["date_parsed"].isna().any():
        st.warning("âš ï¸ æ£€æµ‹åˆ°éƒ¨åˆ†è®°å½•çš„æ—¥æœŸæ— æ³•ä»æ–‡ä»¶åè§£æï¼ˆå»ºè®®ä½¿ç”¨ 2025-11-12 æˆ– 20251112ï¼‰ï¼Œè¿™äº›è®°å½•å°†è¢«å¿½ç•¥ã€‚")
        import_data = import_data[~import_data["date_parsed"].isna()].copy()

    return import_data

# =========================
# Step 1: å¤„ç† Provider æ˜ å°„æ–‡ä»¶
# =========================
provider_map = pd.DataFrame()
if provider_file:
    try:
        provider_map = pd.read_excel(provider_file)
        provider_map = normalize_columns(provider_map)
        if "providername" not in provider_map.columns or "providerid" not in provider_map.columns:
            st.error("Provider æ˜ å°„æ–‡ä»¶å¿…é¡»åŒ…å«åˆ—ï¼šProviderName å’Œ ProviderId")
            st.stop()
        provider_map = provider_map.drop_duplicates(subset=["providerid"]).reset_index(drop=True)
    except Exception as e:
        st.error(f"è¯»å– Provider æ˜ å°„å¤±è´¥ï¼š{e}")
        st.stop()

# =========================
# Step 2: å¤„ç†æ±‡å…¥é‡æ–‡ä»¶ & èŠ‚å‡æ—¥
# =========================
import_data = prepare_import_data(import_files, provider_map)
holidays_set = load_holidays_set(holidays_file)

# =========================
# åŠŸèƒ½ 1ï¼šå•æ—¥ Provider æ±‡å…¥æ•°é‡åˆ†æ
# =========================
if menu == "åŠŸèƒ½ 1ï¼šå•æ—¥ Provider æ±‡å…¥æ•°é‡åˆ†æ":
    st.subheader("ğŸ“Œ å•æ—¥ Provider æ±‡å…¥æ•°é‡åˆ†æ")
    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        avail_dates = sorted(import_data["date_parsed"].dropna().unique())
        if len(avail_dates) == 0:
            st.warning("æ²¡æœ‰å¯ç”¨çš„æœ‰æ•ˆæ—¥æœŸæ•°æ®ã€‚")
        else:
            date_strs = [pd.to_datetime(d).strftime("%Y-%m-%d") for d in avail_dates]
            selected_date_str = st.selectbox("é€‰æ‹©æ—¥æœŸ", date_strs)
            selected_date = pd.to_datetime(selected_date_str).date()

            day_data = import_data[import_data["date_parsed"] == selected_date]
            provider_counts = (
                day_data.groupby("provider_label", dropna=False)["importcount"]
                .sum()
                .reset_index()
                .sort_values(by="importcount", ascending=False)
            )

            st.write("å„ Provider æ±‡å…¥æ•°é‡ï¼š")
            st.dataframe(provider_counts, use_container_width=True)

            fig = px.bar(provider_counts, x="provider_label", y="importcount",
                         labels={"provider_label": "Provider", "importcount": "æ±‡å…¥æ•°é‡"},
                         title=f"{selected_date_str} å„ Provider æ±‡å…¥æ•°é‡")
            st.plotly_chart(fig, use_container_width=True)

            export_excel(provider_counts, f"Provider_Import_{selected_date_str}.xlsx")

# =========================
# åŠŸèƒ½ 2ï¼šå¤šæ—¥è¶‹åŠ¿åˆ†æï¼ˆåˆ†ç»„æ˜¾ç¤ºï¼‰ + æ¬¡çº§åŠŸèƒ½
# =========================
elif menu == "åŠŸèƒ½ 2ï¼šå¤šæ—¥è¶‹åŠ¿åˆ†æï¼ˆåˆ†ç»„æ˜¾ç¤ºï¼‰":
    st.subheader("ğŸ“Œ å¤šæ—¥è¶‹åŠ¿åˆ†æï¼ˆæŒ‰ Provider åˆ†ç»„ï¼Œæ¯ç»„ 10 ä¸ªï¼‰")

    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        # ---------- Provider ç™½åå•ï¼ˆåŠ¨æ€æä¾›ï¼‰ ----------
        all_providers = sorted(import_data["provider_label"].dropna().unique().tolist())
        whitelist = st.sidebar.multiselect("Provider ç™½åå•ï¼ˆåªçœ‹é€‰ä¸­é¡¹ï¼›ç•™ç©ºè¡¨ç¤ºæŸ¥çœ‹å…¨éƒ¨ï¼‰", options=all_providers, default=[])

        # ä¸¤ä¸ªæ¬¡çº§åŠŸèƒ½æ ‡ç­¾é¡µ
        tab_workdays, tab_all = st.tabs(["å·¥ä½œæ—¥ç»Ÿè®¡ï¼ˆå«èŠ‚å‡æ—¥å¼€å…³ï¼‰", "å…¨é‡ç»Ÿè®¡ï¼ˆåŒ…å«å‘¨æœ«ä¸èŠ‚å‡æ—¥ï¼‰"])

        # ===== æ¬¡çº§åŠŸèƒ½ 1ï¼šå·¥ä½œæ—¥ç»Ÿè®¡ï¼ˆå«èŠ‚å‡æ—¥å¼€å…³ï¼‰ =====
        with tab_workdays:
            st.markdown("### ğŸ—“ï¸ ä»…ç»Ÿè®¡å·¥ä½œæ—¥ï¼ˆå‘¨ä¸€~å‘¨äº”ï¼‰ï¼Œå¯é€‰æ‹©æ˜¯å¦æ’é™¤èŠ‚å‡æ—¥")
            df = import_data.copy()

            # Provider ç™½åå•ç­›é€‰
            if whitelist:
                df = df[df["provider_label"].isin(whitelist)].copy()

            # ä»…å·¥ä½œæ—¥
            df["weekday"] = pd.to_datetime(df["date_parsed"]).dt.weekday  # å‘¨ä¸€=0 ... å‘¨æ—¥=6
            df = df[df["weekday"] < 5].copy()

            # å¼€å…³ï¼šæ˜¯å¦åŒæ—¶æ’é™¤èŠ‚å‡æ—¥
            use_holidays = st.checkbox("åŒæ—¶æ’é™¤èŠ‚å‡æ—¥ï¼ˆæ¥è‡ªä¸Šä¼ çš„ holidays.csvï¼‰", value=True, key="workdays_use_holidays")
            if use_holidays:
                if len(holidays_set) > 0:
                    before_n = len(df)
                    df = df[~df["date_parsed"].isin(holidays_set)].copy()
                    st.caption(f"å·²æ’é™¤æ³•å®šèŠ‚å‡æ—¥ï¼šç§»é™¤ {before_n - len(df)} è¡Œï¼ˆholidays.csv å…± {len(holidays_set)} å¤©ï¼‰")
                else:
                    st.warning("å·²å¼€å¯â€œåŒæ—¶æ’é™¤èŠ‚å‡æ—¥â€ï¼Œä½†æœªä¸Šä¼  holidays.csvã€‚å½“å‰ä»…æ’é™¤å‘¨æœ«ã€‚")

            if df.empty:
                st.warning("è¿‡æ»¤åæ— æ•°æ®ï¼Œè¯·æ£€æŸ¥æ—¥æœŸæˆ–èŠ‚å‡æ—¥è®¾ç½®ã€ç™½åå•é€‰æ‹©ã€‚")
            else:
                # é¡¶éƒ¨å¼‚å¸¸æŠ¥è­¦ï¼ˆåŸºäºè¿‡æ»¤åçš„æ•°æ®ï¼‰
                daily_import = (
                    df.groupby(["providerid", "provider_label", "date_parsed"], dropna=False)["importcount"]
                    .sum()
                    .reset_index()
                    .rename(columns={"date_parsed": "date"})
                )
                anomaly_alerts_block(daily_import, title_latest_day="æœ€æ–°å·¥ä½œæ—¥", anomaly_filename_prefix="WorkdaysOnly",
                                     threshold_pct=alert_threshold_pct)

                # è¶‹åŠ¿å›¾ï¼ˆåˆ†ç»„æ˜¾ç¤ºï¼‰
                provider_total = df.groupby("provider_label", dropna=False)["importcount"].sum().sort_values(ascending=False)
                providers_sorted = provider_total.index.tolist()
                group_size = 10
                provider_groups = [providers_sorted[i:i+group_size] for i in range(0, len(providers_sorted), group_size)]

                trend_data = (
                    df.groupby(["date_parsed", "provider_label"], dropna=False)["importcount"]
                    .sum()
                    .reset_index()
                    .rename(columns={"date_parsed": "date"})
                    .sort_values(by="date")
                )

                all_group_data = []
                for idx, group in enumerate(provider_groups, start=1):
                    st.markdown(f"#### ç¬¬ {idx} ç»„è¶‹åŠ¿å›¾ï¼ˆå·¥ä½œæ—¥ï¼‰")
                    group_data = trend_data[trend_data["provider_label"].isin(group)]
                    all_group_data.append(group_data)
                    fig = px.line(group_data, x="date", y="importcount", color="provider_label",
                                  labels={"provider_label": "Provider", "importcount": "æ±‡å…¥æ•°é‡", "date": "æ—¥æœŸ"},
                                  title=f"Provider è¶‹åŠ¿åˆ†æï¼ˆç¬¬ {idx} ç»„ï¼Œå·¥ä½œæ—¥ï¼‰", markers=True)
                    st.plotly_chart(fig, use_container_width=True)

                if all_group_data:
                    export_excel(pd.concat(all_group_data), "Provider_Trend_WorkdaysOnly.xlsx")

        # ===== æ¬¡çº§åŠŸèƒ½ 2ï¼šå…¨é‡ç»Ÿè®¡ï¼ˆåŒ…å«å‘¨æœ«ä¸èŠ‚å‡æ—¥ï¼‰ =====
        with tab_all:
            st.markdown("### ğŸ“… å…¨é‡æ•°æ®é›†ï¼ˆåŒ…å«å‘¨æœ«ä¸èŠ‚å‡æ—¥ï¼‰")
            df = import_data.copy()

            # Provider ç™½åå•ç­›é€‰
            if whitelist:
                df = df[df["provider_label"].isin(whitelist)].copy()

            if df.empty:
                st.warning("å…¨é‡æ•°æ®é›†ä¸ºç©ºï¼ˆå¯èƒ½è¢«ç™½åå•ç­›é€‰ä¸ºç©ºï¼‰ã€‚")
            else:
                # é¡¶éƒ¨å¼‚å¸¸æŠ¥è­¦ï¼ˆåŸºäºå…¨é‡æ•°æ®ï¼‰
                daily_import = (
                    df.groupby(["providerid", "provider_label", "date_parsed"], dropna=False)["importcount"]
                    .sum()
                    .reset_index()
                    .rename(columns={"date_parsed": "date"})
                )
                anomaly_alerts_block(daily_import, title_latest_day="æœ€æ–°ä¸€å¤©", anomaly_filename_prefix="AllIncluded",
                                     threshold_pct=alert_threshold_pct)

                # è¶‹åŠ¿å›¾ï¼ˆåˆ†ç»„æ˜¾ç¤ºï¼‰
                provider_total = df.groupby("provider_label", dropna=False)["importcount"].sum().sort_values(ascending=False)
                providers_sorted = provider_total.index.tolist()
                group_size = 10
                provider_groups = [providers_sorted[i:i+group_size] for i in range(0, len(providers_sorted), group_size)]

                trend_data = (
                    df.groupby(["date_parsed", "provider_label"], dropna=False)["importcount"]
                    .sum()
                    .reset_index()
                    .rename(columns={"date_parsed": "date"})
                    .sort_values(by="date")
                )

                all_group_data = []
                for idx, group in enumerate(provider_groups, start=1):
                    st.markdown(f"#### ç¬¬ {idx} ç»„è¶‹åŠ¿å›¾ï¼ˆå…¨é‡ï¼‰")
                    group_data = trend_data[trend_data["provider_label"].isin(group)]
                    all_group_data.append(group_data)
                    fig = px.line(group_data, x="date", y="importcount", color="provider_label",
                                  labels={"provider_label": "Provider", "importcount": "æ±‡å…¥æ•°é‡", "date": "æ—¥æœŸ"},
                                  title=f"å…¨é‡ Provider è¶‹åŠ¿åˆ†æï¼ˆç¬¬ {idx} ç»„ï¼‰", markers=True)
                    st.plotly_chart(fig, use_container_width=True)

                if all_group_data:
                    export_excel(pd.concat(all_group_data), "Provider_Trend_AllIncluded.xlsx")