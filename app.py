import streamlit as st
import pandas as pd
import plotly.express as px
import os
from io import BytesIO

# =========================
# é¡µé¢é…ç½®ä¸æ ·å¼
# =========================
st.set_page_config(page_title="MSN Provider Insight", layout="wide")

st.markdown("""
<style>
.app-main-title h1 {
    font-size: 2.50rem !important;
    font-weight: 800;
    margin: 0 !important;
    padding: 0 !important;
}
.page-title {
    font-size: 1.60rem !important;
    font-weight: 700;
    margin: 0.2rem 0 0.6rem 0;
}
.page-subtitle { display: none; }
.alert-exclam { color: #d00000; font-weight: 800; font-size: 16px; margin-right: 6px; }
.alert-line { font-size: 14px; line-height: 1.6; }
.alert-box { padding: 8px 10px; background-color: #fff5f5; border-left: 4px solid #d00000; border-radius: 6px; margin-bottom: 12px; }
.section-title {
    font-size: 1.05rem !important;
    font-weight: 600;
    margin: 0.4rem 0 0.4rem 0;
}
</style>
""", unsafe_allow_html=True)

# é¡¶éƒ¨ä¸»æ ‡é¢˜
st.markdown("<div class='app-main-title'><h1>MSN Provider Insight</h1></div>", unsafe_allow_html=True)

# =========================
# èœå•
# =========================
menu = st.sidebar.radio("é€‰æ‹©åŠŸèƒ½", [
    "åŠŸèƒ½ 1ï¼šå•æ—¥åˆ†æ",
    "åŠŸèƒ½ 2ï¼šä»…å·¥ä½œæ—¥",
    "åŠŸèƒ½ 3ï¼šä»…å‘¨æœ«",
    "åŠŸèƒ½ 4ï¼šå…¨éƒ¨æ•°æ®"
])

# =========================
# ä¾§è¾¹æ ï¼šä¸Šä¼ ä¸å‚æ•°
# =========================
st.sidebar.markdown("ğŸ—‚ï¸ æ–‡ä»¶ä¸Šä¼ ")
provider_file = st.sidebar.file_uploader("ä¸Šä¼  Provider ID & Name", type=["xlsx"])
import_files = st.sidebar.file_uploader("ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶", type=["xlsx"], accept_multiple_files=True)
holidays_file = st.sidebar.file_uploader("ä¸Šä¼ èŠ‚å‡æ—¥", type=["csv"])

st.sidebar.markdown("âš™ï¸ å‚æ•°è®¾ç½®")
# æŠ¥è­¦é˜ˆå€¼ï¼šæœ€ä½ 5%ï¼Œä¸Šé™ä¸è®¾é™
alert_threshold_pct = st.sidebar.number_input("æŠ¥è­¦é˜ˆå€¼ï¼ˆ%ï¼‰", min_value=5.0, value=50.0, step=1.0, format="%.1f")

# =========================
# å·¥å…·å‡½æ•°
# =========================
def export_excel(df, filename):
    output = BytesIO()
    writer = None
    for eng in ("openpyxl", "xlsxwriter"):
        try:
            writer = pd.ExcelWriter(output, engine=eng)
            break
        except Exception:
            writer = None
    if writer is None:
        st.error("ç¼ºå°‘ Excel å†™å…¥å¼•æ“ï¼Œè¯·å®‰è£… openpyxl æˆ– XlsxWriter")
        st.stop()
    with writer:
        df.to_excel(writer, index=False, sheet_name='Sheet1')
    st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœ", output.getvalue(), file_name=filename,
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

def normalize_columns(df):
    df.columns = [col.strip().lower() for col in df.columns]
    return df

def parse_date_series(s):
    return pd.to_datetime(s, errors='coerce').dt.date

def load_holidays_set(uploaded_csv) -> set:
    if uploaded_csv is None:
        return set()
    try:
        df = pd.read_csv(uploaded_csv)
        df = normalize_columns(df)
        if "date" not in df.columns:
            st.error("èŠ‚å‡æ—¥æ–‡ä»¶éœ€åŒ…å«åˆ—ï¼šdate")
            return set()
        df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.date
        df = df.dropna(subset=["date"]).reset_index(drop=True)
        return set(df["date"].tolist())
    except Exception as e:
        st.error(f"è¯»å–èŠ‚å‡æ—¥æ–‡ä»¶å¤±è´¥ï¼š{e}")
        return set()

def prepare_import_data(import_files, provider_map):
    """
    è¯»å–ä¸Šä¼ çš„ import xlsxï¼Œåˆå¹¶ provider_mapï¼Œè§£ææ—¥æœŸï¼Œæ„é€  provider_labelï¼Œ
    å¹¶å¿½ç•¥ ProviderId == 'BBPIRCh' çš„å…¨éƒ¨æ•°æ®ã€‚
    """
    import_data = pd.DataFrame()
    if import_files:
        for file in import_files:
            df = pd.read_excel(file)
            df = normalize_columns(df)
            date_str = os.path.splitext(file.name)[0]
            df["date"] = date_str
            import_data = pd.concat([import_data, df], ignore_index=True)

    if import_data.empty:
        return import_data

    if "providerid" not in import_data.columns or "importcount" not in import_data.columns:
        st.error("æ±‡å…¥é‡æ–‡ä»¶éœ€åŒ…å«åˆ—ï¼šProviderId ä¸ ImportCount")
        st.stop()

    # ç»Ÿä¸€å­—ç¬¦ä¸²å¹¶è¿‡æ»¤ BBPIRCh
    import_data["providerid_str"] = import_data["providerid"].astype(str)
    import_data = import_data[import_data["providerid_str"] != "BBPIRCh"].copy()

    # åˆå¹¶ Provider åç§°
    if not provider_map.empty:
        import_data = import_data.merge(provider_map, on="providerid", how="left")

    # Provider æ˜¾ç¤ºæ ‡ç­¾ï¼ˆä¼˜å…ˆ providernameï¼Œå¦åˆ™ç”¨ providerid_strï¼‰
    if "providername" in import_data.columns:
        import_data["provider_label"] = import_data["providername"].where(import_data["providername"].notna(),
                                                                         import_data["providerid_str"])
    else:
        import_data["provider_label"] = import_data["providerid_str"]

    # è§£ææ—¥æœŸ
    import_data["date_parsed"] = parse_date_series(import_data["date"])
    if import_data["date_parsed"].isna().any():
        st.warning("å‘ç°æ— æ•ˆæ—¥æœŸè®°å½•ï¼Œå·²å¿½ç•¥")
        import_data = import_data[~import_data["date_parsed"].isna()].copy()

    return import_data

def filter_cn_named(df: pd.DataFrame) -> pd.DataFrame:
    """
    ä»…ä¿ç•™æœ‰ä¸­æ–‡ ProviderName çš„è®°å½•ï¼ˆç”¨äºåŠŸèƒ½ 2/3/4ï¼‰ã€‚
    æ— æ˜ å°„æ—¶ï¼ˆæ—  providername åˆ—ï¼‰è¿”å›ç©ºï¼Œä»¥æ»¡è¶³â€œåªæœ‰ ID çš„æ’é™¤ä¸ç”¨ç»Ÿè®¡â€çš„è¦æ±‚ã€‚
    """
    if df.empty:
        return df
    if "providername" not in df.columns:
        return df.iloc[0:0].copy()
    mask = df["providername"].notna() & (df["providername"].astype(str).str.strip() != "")
    return df[mask].copy()

def plot_grouped_trends(trend_data: pd.DataFrame, providers_sorted: list, group_size: int, export_name: str):
    """åˆ†ç»„ç»˜å›¾ï¼ˆX è½´æ¯æ—¥æ˜¾ç¤ºï¼‰ï¼Œå¹¶å¯¼å‡º Excel"""
    provider_groups = [providers_sorted[i:i+group_size] for i in range(0, len(providers_sorted), group_size)]
    all_group_data = []
    for idx, group in enumerate(provider_groups, start=1):
        st.markdown(f"<div class='section-title'>ğŸ“ˆ ç¬¬ {idx} ç»„</div>", unsafe_allow_html=True)
        group_data = trend_data[trend_data["provider_label"].isin(group)].copy()
        all_group_data.append(group_data)
        fig = px.line(group_data, x="date_str", y="importcount", color="provider_label",
                      labels={"provider_label": "Provider", "importcount": "æ±‡å…¥æ•°é‡", "date_str": "æ—¥æœŸ"},
                      title="")
        fig.update_xaxes(type="category", categoryorder="category ascending", tickangle=-45)
        st.plotly_chart(fig, use_container_width=True)
    if all_group_data:
        export_excel(pd.concat(all_group_data), export_name)

# =========================
# Provider æ˜ å°„
# =========================
provider_map = pd.DataFrame()
if provider_file:
    try:
        provider_map = pd.read_excel(provider_file)
        provider_map = normalize_columns(provider_map)
        if "providername" not in provider_map.columns or "providerid" not in provider_map.columns:
            st.error("Provider æ˜ å°„éœ€åŒ…å«ï¼šProviderName ä¸ ProviderId")
            st.stop()
        provider_map = provider_map.drop_duplicates(subset=["providerid"]).reset_index(drop=True)
    except Exception as e:
        st.error(f"è¯»å– Provider æ˜ å°„å¤±è´¥ï¼š{e}")
        st.stop()

# =========================
# æ±‡å…¥é‡ä¸èŠ‚å‡æ—¥
# =========================
import_data = prepare_import_data(import_files, provider_map)
holidays_set = load_holidays_set(holidays_file)

# =========================
# æŠ¥è­¦é€»è¾‘ï¼ˆæœ€æ–°ä¸€å¤© vs å‰ä¸€å¤©ï¼›æœ€æ–°ä¸€å¤© > 500 æ‰åˆ¤å®šï¼‰
# =========================
def anomaly_alerts_block_dod_latest_gt500(df_daily: pd.DataFrame, title_latest_day: str, filename_prefix: str, threshold_pct: float):
    """
    DoD æŠ¥è­¦ï¼š
    - ä»…å¯¹â€œæœ€æ–°ä¸€å¤©æ±‡å…¥é‡ > 500â€çš„ Provider å‚ä¸åˆ¤æ–­ï¼›
    - æ¡ä»¶ï¼š|æœ€æ–° - å‰ä¸€æ—¥| / å‰ä¸€æ—¥ â‰¥ é˜ˆå€¼ï¼›
    - å‰ä¸€æ—¥=0 ä¸”æœ€æ–°>500ï¼Œè§†ä¸ºå˜åŒ–æ— é™å¤§ï¼ˆåˆ¤ä¸ºâ€œå‡é«˜â€ï¼‰ã€‚
    """
    if df_daily.empty or df_daily["date"].isna().all():
        st.warning("æ— å¯ç”¨æ—¥æœŸæ•°æ®")
        return

    dates_sorted = sorted(df_daily["date"].dropna().unique())
    if len(dates_sorted) < 2:
        st.markdown("<div class='alert-box'>æ•°æ®ä¸è¶³ 2 å¤©ï¼Œæ— æ³•è¿›è¡Œä¸å‰ä¸€å¤©çš„æ¯”è¾ƒ</div>", unsafe_allow_html=True)
        return

    latest_date = dates_sorted[-1]
    prev_date = dates_sorted[-2]

    latest_df = (df_daily[df_daily["date"] == latest_date]
                 .groupby(["providerid", "provider_label"], dropna=False)["importcount"]
                 .sum().reset_index().rename(columns={"importcount": "latest_count"}))
    prev_df = (df_daily[df_daily["date"] == prev_date]
               .groupby(["providerid", "provider_label"], dropna=False)["importcount"]
               .sum().reset_index().rename(columns={"importcount": "prev_count"}))

    comp = pd.merge(latest_df, prev_df, on=["providerid", "provider_label"], how="left")

    # ä»…ä¿ç•™â€œæœ€æ–°ä¸€å¤© > 500â€çš„ Provider
    comp = comp[comp["latest_count"] > 500].copy()

    if comp.empty:
        st.markdown(
            f"<div class='alert-box'>âœ… {title_latest_day}ï¼ˆ{pd.to_datetime(latest_date).strftime('%Y/%m/%d')}ï¼‰æ— æ»¡è¶³åŸºçº¿æ¡ä»¶ï¼ˆæœ€æ–°>500ï¼‰çš„ Provider</div>",
            unsafe_allow_html=True
        )
        return

    # è®¡ç®—ç›¸å¯¹å˜åŒ–
    def calc_ratio(row):
        prev = row["prev_count"] if pd.notna(row["prev_count"]) else 0
        now = row["latest_count"]
        if prev == 0:
            return float("inf") if now > 0 else 0.0
        return (now - prev) / prev

    comp["change_ratio"] = comp.apply(calc_ratio, axis=1)
    comp["direction"] = comp.apply(lambda r: "å‡é«˜" if r["latest_count"] >= (r["prev_count"] if pd.notna(r["prev_count"]) else 0) else "å‡å°‘", axis=1)
    threshold_ratio = float(threshold_pct) / 100.0
    alerts_df = comp[comp["change_ratio"].abs() >= threshold_ratio].copy()

    # é¡¶éƒ¨æ€»æ ‡é¢˜ï¼ˆæç¤ºæ¯”è¾ƒçš„ä¸¤å¤©ï¼‰
    st.markdown(
        f"<div class='alert-box'><b>ğŸš¨ å¼‚å¸¸æŠ¥è­¦ï¼ˆ{title_latest_day}ï¼š{pd.to_datetime(latest_date).strftime('%Y/%m/%d')} å¯¹æ¯” {pd.to_datetime(prev_date).strftime('%Y/%m/%d')}ï¼Œé˜ˆå€¼ {threshold_pct:.1f}%ï¼‰</b></div>",
        unsafe_allow_html=True
    )

    if alerts_df.empty:
        st.markdown("<div class='alert-box'>âœ… æœªå‘ç°å¼‚å¸¸æ³¢åŠ¨ï¼ˆæ»¡è¶³æ¡ä»¶çš„ Providerï¼‰</div>", unsafe_allow_html=True)
    else:
        # æ¯ä¸ª Provider ä¸€è¡Œï¼Œæ ¼å¼ï¼šè­¦ç¯icon + å¼‚å¸¸æŠ¥è­¦ + XX Provideræœ€æ–°ä¸€å¤©æ±‡å…¥é‡å¼‚å¸¸å‡é«˜/å‡å°‘
        for _, row in alerts_df.sort_values(by="change_ratio", key=lambda s: s.abs(), ascending=False).iterrows():
            msg = f"ğŸš¨å¼‚å¸¸æŠ¥è­¦ {row['provider_label']}æœ€æ–°ä¸€å¤©æ±‡å…¥é‡å¼‚å¸¸{row['direction']}"
            st.markdown(f"<div class='alert-line'>{msg}</div>", unsafe_allow_html=True)

        # æ˜ç»†å¯¼å‡ºï¼ˆå¯é€‰ï¼‰
        pretty = alerts_df.copy()
        pretty = pretty.rename(columns={
            "providerid": "ProviderId",
            "provider_label": "Provider",
            "latest_count": "æœ€æ–°æ—¥æ±‡å…¥é‡",
            "prev_count": "å‰ä¸€æ—¥æ±‡å…¥é‡",
        })
        pretty["æœ€æ–°æ—¥æœŸ"] = pd.to_datetime(latest_date).strftime("%Y/%m/%d")
        pretty["å‰ä¸€æ—¥æœŸ"] = pd.to_datetime(prev_date).strftime("%Y/%m/%d")
        pretty["å˜åŒ–æ¯”ä¾‹"] = pretty["change_ratio"].apply(lambda x: "âˆ" if x == float("inf") else f"{(x*100):.2f}%")

        cols = ["ProviderId", "Provider", "å‰ä¸€æ—¥æœŸ", "å‰ä¸€æ—¥æ±‡å…¥é‡", "æœ€æ–°æ—¥æœŸ", "æœ€æ–°æ—¥æ±‡å…¥é‡", "å˜åŒ–æ¯”ä¾‹", "direction"]
        pretty = pretty[cols]
        with st.expander("æŸ¥çœ‹æŠ¥è­¦æ˜ç»†", expanded=False):
            st.dataframe(pretty, use_container_width=True)
            export_excel(pretty, f"{filename_prefix}_æŠ¥è­¦æ˜ç»†_{pd.to_datetime(latest_date).strftime('%Y%m%d')}.xlsx")

# =========================
# åŠŸèƒ½ 1ï¼šå•æ—¥åˆ†æï¼ˆä¿æŒä¸å˜ï¼‰
# =========================
if menu == "åŠŸèƒ½ 1ï¼šå•æ—¥åˆ†æ":
    st.markdown("<div class='page-title'>ğŸ—“ï¸ğŸ“Š å•æ—¥åˆ†æ</div>", unsafe_allow_html=True)
    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        dates = sorted(import_data["date_parsed"].dropna().unique())
        if not dates:
            st.warning("æ— æœ‰æ•ˆæ—¥æœŸ")
        else:
            date_strs = [pd.to_datetime(d).strftime("%Y-%m-%d") for d in dates]
            selected_date_str = st.selectbox("é€‰æ‹©æ—¥æœŸ", date_strs)
            selected_date = pd.to_datetime(selected_date_str).date()

            day_data = import_data[import_data["date_parsed"] == selected_date]
            provider_counts = (day_data.groupby("provider_label", dropna=False)["importcount"]
                               .sum().reset_index().sort_values(by="importcount", ascending=False))
            provider_counts = provider_counts.rename(columns={"provider_label": "Provider", "importcount": "æ±‡å…¥æ•°é‡"})

            st.dataframe(provider_counts, use_container_width=True)
            fig = px.bar(provider_counts, x="Provider", y="æ±‡å…¥æ•°é‡", title=f"{selected_date_str} æ±‡å…¥æ•°é‡")
            st.plotly_chart(fig, use_container_width=True)

            export_excel(provider_counts, f"å•æ—¥_æ±‡å…¥_{selected_date_str}.xlsx")

# =========================
# åŠŸèƒ½ 2ï¼šä»…å·¥ä½œæ—¥ï¼ˆæœ€æ–°æ—¥æ’åºåˆ†ç»„ï¼Œæ¯ 10 ä¸ªä¸€ç»„ï¼‰
# =========================
elif menu == "åŠŸèƒ½ 2ï¼šä»…å·¥ä½œæ—¥":
    st.markdown("<div class='page-title'>ğŸ§‘â€ğŸ’¼ğŸ“ˆ ä»…å·¥ä½œæ—¥</div>", unsafe_allow_html=True)
    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        df = import_data.copy()
        # ä»…å·¥ä½œæ—¥
        df["weekday"] = pd.to_datetime(df["date_parsed"]).dt.weekday
        df = df[df["weekday"] < 5].copy()

        # æ’é™¤èŠ‚å‡æ—¥ï¼ˆå¯é€‰ï¼‰
        use_holidays = st.checkbox("æ’é™¤èŠ‚å‡æ—¥", value=True, key="workdays_holiday_toggle")
        if use_holidays:
            if len(holidays_set) > 0:
                df = df[~df["date_parsed"].isin(holidays_set)].copy()
            else:
                st.info("æœªæä¾›èŠ‚å‡æ—¥æ–‡ä»¶")

        # ä»…ä¸­æ–‡ ProviderName
        df = filter_cn_named(df)
        if df.empty:
            st.warning("æ— æ•°æ®")
        else:
            # ç™½åå•ï¼ˆä¸­æ–‡ï¼‰
            all_providers = sorted(df["provider_label"].dropna().unique().tolist())
            whitelist = st.sidebar.multiselect("Provider ç­›é€‰", options=all_providers, default=[])
            if whitelist:
                df = df[df["provider_label"].isin(whitelist)].copy()

            if df.empty:
                st.warning("æ— æ•°æ®")
            else:
                # é¡¶éƒ¨æŠ¥è­¦ï¼šæœ€æ–° vs å‰ä¸€å¤©ï¼ˆæœ€æ–°>500ï¼‰
                daily_import = (df.groupby(["providerid", "provider_label", "date_parsed"], dropna=False)["importcount"]
                                .sum().reset_index().rename(columns={"date_parsed": "date"}))
                anomaly_alerts_block_dod_latest_gt500(daily_import, "æœ€æ–°å·¥ä½œæ—¥", "ä»…å·¥ä½œæ—¥", alert_threshold_pct)

                # åˆ†ç»„æ’åºä¾æ®ï¼šæœ€æ–°ä¸€å¤©æ±‡å…¥é‡
                latest_date = daily_import["date"].max()
                latest_day_counts = (daily_import[daily_import["date"] == latest_date]
                                     .groupby("provider_label", dropna=False)["importcount"]
                                     .sum().sort_values(ascending=False))
                providers_sorted = latest_day_counts.index.tolist()
                if not providers_sorted:
                    provider_total = df.groupby("provider_label", dropna=False)["importcount"].sum().sort_values(ascending=False)
                    providers_sorted = provider_total.index.tolist()

                # è¶‹åŠ¿æ•°æ® & æ¯æ—¥æ—¥æœŸå­—ç¬¦ä¸²
                trend_data = (df.groupby(["date_parsed", "provider_label"], dropna=False)["importcount"]
                              .sum().reset_index().rename(columns={"date_parsed": "date"}))
                trend_data["date_str"] = pd.to_datetime(trend_data["date"]).dt.strftime("%Y-%m-%d")

                # ç»˜å›¾ä¸å¯¼å‡º
                plot_grouped_trends(trend_data, providers_sorted, group_size=10, export_name="è¶‹åŠ¿_ä»…å·¥ä½œæ—¥.xlsx")

# =========================
# åŠŸèƒ½ 3ï¼šä»…å‘¨æœ«ï¼ˆæ€»é‡æ’åºåˆ†ç»„ï¼‰
# =========================
elif menu == "åŠŸèƒ½ 3ï¼šä»…å‘¨æœ«":
    st.markdown("<div class='page-title'>ğŸ›ŒğŸ“ˆ ä»…å‘¨æœ«</div>", unsafe_allow_html=True)
    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        df = import_data.copy()
        # ä»…å‘¨æœ«
        df["weekday"] = pd.to_datetime(df["date_parsed"]).dt.weekday
        df = df[df["weekday"] >= 5].copy()

        # ä»…ä¸­æ–‡ ProviderName
        df = filter_cn_named(df)
        if df.empty:
            st.warning("æ— æ•°æ®")
        else:
            # ç™½åå•ï¼ˆä¸­æ–‡ï¼‰
            all_providers = sorted(df["provider_label"].dropna().unique().tolist())
            whitelist = st.sidebar.multiselect("Provider ç­›é€‰", options=all_providers, default=[], key="wl_weekends")
            if whitelist:
                df = df[df["provider_label"].isin(whitelist)].copy()

            if df.empty:
                st.warning("æ— æ•°æ®")
            else:
                # é¡¶éƒ¨æŠ¥è­¦ï¼šæœ€æ–° vs å‰ä¸€å¤©ï¼ˆæœ€æ–°>500ï¼‰
                daily_import = (df.groupby(["providerid", "provider_label", "date_parsed"], dropna=False)["importcount"]
                                .sum().reset_index().rename(columns={"date_parsed": "date"}))
                anomaly_alerts_block_dod_latest_gt500(daily_import, "æœ€æ–°å‘¨æœ«æ—¥", "ä»…å‘¨æœ«", alert_threshold_pct)

                # åˆ†ç»„ï¼šæ€»é‡æ’åº
                trend_data = (df.groupby(["date_parsed", "provider_label"], dropna=False)["importcount"]
                              .sum().reset_index().rename(columns={"date_parsed": "date"}))
                trend_data["date_str"] = pd.to_datetime(trend_data["date"]).dt.strftime("%Y-%m-%d")
                provider_total = trend_data.groupby("provider_label")["importcount"].sum().sort_values(ascending=False)
                providers_sorted = provider_total.index.tolist()

                plot_grouped_trends(trend_data, providers_sorted, group_size=10, export_name="è¶‹åŠ¿_ä»…å‘¨æœ«.xlsx")

# =========================
# åŠŸèƒ½ 4ï¼šå…¨éƒ¨æ•°æ®ï¼ˆæ€»é‡æ’åºåˆ†ç»„ï¼‰
# =========================
elif menu == "åŠŸèƒ½ 4ï¼šå…¨éƒ¨æ•°æ®":
    st.markdown("<div class='page-title'>ğŸ“šğŸ“ˆ å…¨éƒ¨æ•°æ®</div>", unsafe_allow_html=True)
    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        df = import_data.copy()
        # ä»…ä¸­æ–‡ ProviderName
        df = filter_cn_named(df)
        if df.empty:
            st.warning("æ— æ•°æ®")
        else:
            # ç™½åå•ï¼ˆä¸­æ–‡ï¼‰
            all_providers = sorted(df["provider_label"].dropna().unique().tolist())
            whitelist = st.sidebar.multiselect("Provider ç­›é€‰", options=all_providers, default=[], key="wl_all")
            if whitelist:
                df = df[df["provider_label"].isin(whitelist)].copy()

            if df.empty:
                st.warning("æ— æ•°æ®")
            else:
                # é¡¶éƒ¨æŠ¥è­¦ï¼šæœ€æ–° vs å‰ä¸€å¤©ï¼ˆæœ€æ–°>500ï¼‰
                daily_import = (df.groupby(["providerid", "provider_label", "date_parsed"], dropna=False)["importcount"]
                                .sum().reset_index().rename(columns={"date_parsed": "date"}))
                anomaly_alerts_block_dod_latest_gt500(daily_import, "æœ€æ–°ä¸€å¤©", "å…¨éƒ¨æ•°æ®", alert_threshold_pct)

                # åˆ†ç»„ï¼šæ€»é‡æ’åº
                trend_data = (df.groupby(["date_parsed", "provider_label"], dropna=False)["importcount"]
                              .sum().reset_index().rename(columns={"date_parsed": "date"}))
                trend_data["date_str"] = pd.to_datetime(trend_data["date"]).dt.strftime("%Y-%m-%d")
                provider_total = trend_data.groupby("provider_label")["importcount"].sum().sort_values(ascending=False)
                providers_sorted = provider_total.index.tolist()

                plot_grouped_trends(trend_data, providers_sorted, group_size=10, export_name="è¶‹åŠ¿_å…¨éƒ¨æ•°æ®.xlsx")