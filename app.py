
import streamlit as st
import pandas as pd
import plotly.express as px
import os
from io import BytesIO
from datetime import date as date_cls

# =========================
# é¡µé¢é…ç½®ä¸æ ·å¼
# =========================
st.set_page_config(page_title="MSN Provider Insight", layout="wide")

st.markdown("""
<style>
.app-main-title h1 {
    font-size: 2.50rem !important;
    font-weight: 800;
    margin: 0 !important;
    padding: 0 !important;
}
.page-title {
    font-size: 1.60rem !important;
    font-weight: 700;
    margin: 0.2rem 0 0.6rem 0;
}
.alert-exclam { color: #d00000; font-weight: 800; font-size: 16px; margin-right: 6px; }
.alert-line { font-size: 14px; line-height: 1.6; }
.alert-box { padding: 8px 10px; background-color: #fff5f5; border-left: 4px solid #d00000; border-radius: 6px; margin-bottom: 12px; }
.section-title {
    font-size: 1.05rem !important;
    font-weight: 600;
    margin: 0.4rem 0 0.4rem 0;
}
</style>
""", unsafe_allow_html=True)

# é¡¶éƒ¨ä¸»æ ‡é¢˜
st.markdown("<div class='app-main-title'><h1>MSN Provider Insight</h1></div>", unsafe_allow_html=True)

# =========================
# èœå•
# =========================
menu = st.sidebar.radio("é€‰æ‹©åŠŸèƒ½", [
    "åŠŸèƒ½ 1ï¼šå•æ—¥åˆ†æ",
    "åŠŸèƒ½ 2ï¼šä»…å·¥ä½œæ—¥",
    "åŠŸèƒ½ 3ï¼šä»…å‘¨æœ«",
    "åŠŸèƒ½ 4ï¼šå…¨éƒ¨æ•°æ®"
])

# =========================
# ä¾§è¾¹æ ï¼šä¸Šä¼ ä¸å‚æ•°
# =========================
st.sidebar.markdown("ğŸ—‚ï¸ æ–‡ä»¶ä¸Šä¼ ")
provider_file = st.sidebar.file_uploader("ä¸Šä¼  Provider ID & Name", type=["xlsx"])
import_files = st.sidebar.file_uploader("ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶", type=["xlsx"], accept_multiple_files=True)
holidays_file = st.sidebar.file_uploader("ä¸Šä¼ èŠ‚å‡æ—¥", type=["csv"])

st.sidebar.markdown("âš™ï¸ å‚æ•°è®¾ç½®")
alert_threshold_pct = st.sidebar.number_input("æŠ¥è­¦é˜ˆå€¼ï¼ˆ%ï¼‰", min_value=5.0, value=50.0, step=1.0, format="%.1f")

# æ±‡å…¥æ€»ç»“å¿½ç•¥åå•ï¼ˆä»…åŠŸèƒ½ 2ï¼‰
EXCLUDED_PROVIDERS_IN_SUMMARY = {"ä¸€ç‚¹èµ„è®¯-è§†é¢‘", "è™ç‰™è§†é¢‘"}

# å…¨å±€ç»Ÿè®¡å¿½ç•¥åå•ï¼ˆæ‰€æœ‰åŠŸèƒ½é¡µéƒ½ä¼šå‰”é™¤ï¼‰
EXCLUDED_PROVIDERS_GLOBAL = {"NOWNEWS(ç°¡ä¸­)"}

# =========================
# å·¥å…·å‡½æ•°
# =========================
def export_excel(df, filename):
    output = BytesIO()
    writer = None
    for eng in ("openpyxl", "xlsxwriter"):
        try:
            writer = pd.ExcelWriter(output, engine=eng)
            break
        except Exception:
            writer = None
    if writer is None:
        st.error("ç¼ºå°‘ Excel å†™å…¥å¼•æ“ï¼Œè¯·å®‰è£… openpyxl æˆ– XlsxWriter")
        st.stop()
    with writer:
        df.to_excel(writer, index=False, sheet_name='Sheet1')
    st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœ", output.getvalue(), file_name=filename,
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

def normalize_columns(df):
    df.columns = [col.strip().lower() for col in df.columns]
    return df

def parse_date_series(s):
    return pd.to_datetime(s, errors='coerce').dt.date

def load_holidays_set(uploaded_csv) -> set:
    if uploaded_csv is None:
        return set()
    try:
        df = pd.read_csv(uploaded_csv)
        df = normalize_columns(df)
        if "date" not in df.columns:
            st.error("èŠ‚å‡æ—¥æ–‡ä»¶éœ€åŒ…å«åˆ—ï¼šdate")
            return set()
        df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.date
        df = df.dropna(subset=["date"]).reset_index(drop=True)
        return set(df["date"].tolist())
    except Exception as e:
        st.error(f"è¯»å–èŠ‚å‡æ—¥æ–‡ä»¶å¤±è´¥ï¼š{e}")
        return set()

def prepare_import_data(import_files, provider_map):
    """
    è¯»å–ä¸Šä¼ çš„ import xlsxï¼Œåˆå¹¶ provider_mapï¼Œè§£ææ—¥æœŸï¼Œæ„é€  provider_labelï¼Œ
    å¹¶å¿½ç•¥ ProviderId == 'BBPIRCh' çš„å…¨éƒ¨æ•°æ®ã€‚
    """
    import_data = pd.DataFrame()
    if import_files:
        for file in import_files:
            df = pd.read_excel(file)
            df = normalize_columns(df)
            date_str = os.path.splitext(file.name)[0]
            df["date"] = date_str
            import_data = pd.concat([import_data, df], ignore_index=True)

    if import_data.empty:
        return import_data

    if "providerid" not in import_data.columns or "importcount" not in import_data.columns:
        st.error("æ±‡å…¥é‡æ–‡ä»¶éœ€åŒ…å«åˆ—ï¼šProviderId ä¸ ImportCount")
        st.stop()

    # ç»Ÿä¸€å­—ç¬¦ä¸²å¹¶è¿‡æ»¤ BBPIRCh
    import_data["providerid_str"] = import_data["providerid"].astype(str)
    import_data = import_data[import_data["providerid_str"] != "BBPIRCh"].copy()

    # åˆå¹¶ Provider åç§°
    if not provider_map.empty:
        import_data = import_data.merge(provider_map, on="providerid", how="left")

    # Provider æ˜¾ç¤ºæ ‡ç­¾ï¼ˆä¼˜å…ˆ providernameï¼Œå¦åˆ™ç”¨ providerid_strï¼‰
    if "providername" in import_data.columns:
        import_data["provider_label"] = import_data["providername"].where(import_data["providername"].notna(),
                                                                         import_data["providerid_str"])
    else:
        import_data["provider_label"] = import_data["providerid_str"]

    # è§£ææ—¥æœŸ
    import_data["date_parsed"] = parse_date_series(import_data["date"])
    if import_data["date_parsed"].isna().any():
        st.warning("å‘ç°æ— æ•ˆæ—¥æœŸè®°å½•ï¼Œå·²å¿½ç•¥")
        import_data = import_data[~import_data["date_parsed"].isna()].copy()

    return import_data

def filter_cn_named(df: pd.DataFrame) -> pd.DataFrame:
    """
    ä»…ä¿ç•™æœ‰ä¸­æ–‡ ProviderName çš„è®°å½•ï¼ˆç”¨äºåŠŸèƒ½ 2/3/4ï¼‰ã€‚
    æ— æ˜ å°„æ—¶ï¼ˆæ—  providername åˆ—ï¼‰è¿”å›ç©ºï¼Œä»¥æ»¡è¶³â€œåªæœ‰ ID çš„æ’é™¤ä¸ç”¨ç»Ÿè®¡â€çš„è¦æ±‚ã€‚
    """
    if df.empty:
        return df
    if "providername" not in df.columns:
        return df.iloc[0:0].copy()
    mask = df["providername"].notna() & (df["providername"].astype(str).str.strip() != "")
    return df[mask].copy()

def filter_excluded_providers(df: pd.DataFrame, excluded_names: set) -> pd.DataFrame:
    """å…¨å±€å‰”é™¤æŒ‡å®š Providerï¼ˆæŒ‰ provider_label åŒ¹é…ï¼‰ã€‚"""
    if df.empty or "provider_label" not in df.columns:
        return df
    return df[~df["provider_label"].astype(str).str.strip().isin(excluded_names)].copy()

# =========================
# â­ å…³é”®ï¼šæ„é€ å®Œæ•´æ—¥æœŸåˆ—è¡¨ & è¡¥é½é›¶å€¼è¶‹åŠ¿æ•°æ®
# =========================
def make_date_list(min_d: date_cls, max_d: date_cls, policy: str, use_holidays: bool, holidays_set: set) -> list:
    """
    æ ¹æ®åœºæ™¯ç”Ÿæˆå®Œæ•´æ—¥æœŸåˆ—è¡¨ï¼š
    - policy: 'workdays'ï¼ˆä»…å·¥ä½œæ—¥ï¼‰ã€'weekends'ï¼ˆä»…å‘¨æœ«ï¼‰ã€'all'ï¼ˆæ‰€æœ‰æ—¥ï¼‰
    - use_holidays: ä»…åœ¨ workdays ä¸‹æœ‰æ•ˆï¼ŒTrue åˆ™å‰”é™¤èŠ‚å‡æ—¥
    """
    if pd.isna(min_d) or pd.isna(max_d):
        return []
    all_days = pd.date_range(min_d, max_d, freq="D").date
    if policy == "workdays":
        days = [d for d in all_days if pd.Timestamp(d).weekday() < 5]
        if use_holidays and holidays_set:
            days = [d for d in days if d not in holidays_set]
        return days
    elif policy == "weekends":
        return [d for d in all_days if pd.Timestamp(d).weekday() >= 5]
    else:
        return list(all_days)

def build_complete_trend_data(df: pd.DataFrame, date_list: list, providers_list: list) -> pd.DataFrame:
    """ç”¨â€œå®Œæ•´æ—¥æœŸåˆ—è¡¨ Ã— Provider åˆ—è¡¨â€åšç¬›å¡å°”è¡¥é½ï¼Œç¼ºå¤±å¡« 0ï¼Œå¹¶æ·»åŠ åˆ†ç±»è½´ç”¨çš„ date_strã€‚"""
    if df.empty or len(date_list) == 0 or len(providers_list) == 0:
        return pd.DataFrame(columns=["date_parsed", "provider_label", "importcount", "date", "date_str"])

    agg = (df.groupby(["date_parsed", "provider_label"], dropna=False)["importcount"]
             .sum().reset_index())

    grid = pd.MultiIndex.from_product([date_list, providers_list], names=["date_parsed", "provider_label"]).to_frame(index=False)
    trend = grid.merge(agg, on=["date_parsed", "provider_label"], how="left")
    trend["importcount"] = trend["importcount"].fillna(0)

    trend["date"] = trend["date_parsed"]
    trend["date_str"] = pd.to_datetime(trend["date"]).dt.strftime("%Y-%m-%d")
    return trend

def plot_grouped_trends(trend_data: pd.DataFrame, providers_sorted: list, date_list: list, group_size: int, export_name: str):
    """åˆ†ç»„ç»˜å›¾ï¼ˆX è½´æ¯æ—¥æ˜¾ç¤ºï¼›å¼ºåˆ¶æ˜¾ç¤ºæ‰€æœ‰åˆ»åº¦ï¼‰ï¼Œå¹¶å¯¼å‡º Excelã€‚"""
    if trend_data.empty:
        st.warning("æ— è¶‹åŠ¿æ•°æ®")
        return

    x_categories = [pd.to_datetime(d).strftime("%Y-%m-%d") for d in date_list]

    provider_groups = [providers_sorted[i:i+group_size] for i in range(0, len(providers_sorted), group_size)]
    all_group_data = []
    for idx, group in enumerate(provider_groups, start=1):
        st.markdown(f"<div class='section-title'>ğŸ“ˆ ç¬¬ {idx} ç»„</div>", unsafe_allow_html=True)
        group_data = trend_data[trend_data["provider_label"].isin(group)].copy()
        all_group_data.append(group_data)
        fig = px.line(group_data, x="date_str", y="importcount", color="provider_label",
                      labels={"provider_label": "Provider", "importcount": "æ±‡å…¥æ•°é‡", "date_str": "æ—¥æœŸ"},
                      title="")
        fig.update_xaxes(
            type="category",
            categoryorder="array",
            categoryarray=x_categories,
            tickmode="array",
            tickvals=x_categories,
            tickangle=-60
        )
        st.plotly_chart(fig, use_container_width=True)

    if all_group_data:
        export_excel(pd.concat(all_group_data), export_name)

# =========================
# æŠ¥è­¦é€»è¾‘ï¼ˆæœ€æ–°ä¸€å¤© vs å‰ä¸€å¤©ï¼Œå«â€œé™è‡³ 0â€ä¾‹å¤–ï¼‰
# âœ… è°ƒæ•´ï¼šæŠ¥è­¦æ˜ç»†ä¸æŠ¥è­¦åˆ—è¡¨å‡æŒ‰â€œå‰ä¸€æ—¥æ±‡å…¥é‡â€ä»é«˜åˆ°ä½æ’åº
# =========================
def anomaly_alerts_block_dod_latest_gt500(
    df_daily: pd.DataFrame,
    title_latest_day: str,
    filename_prefix: str,
    threshold_pct: float,
    show_summary: bool = False,
    excluded_providers_in_summary: set = None
):
    """
    DoD æŠ¥è­¦ï¼š
    å€™é€‰ Providerï¼š
      (1) æœ€æ–°ä¸€å¤© > 500ï¼›æˆ–
      (2) æœ€æ–°ä¸€å¤© = 0 ä¸” å‰ä¸€å¤© > 0ï¼ˆé™è‡³ 0 ä¾‹å¤–ï¼‰
    æ¡ä»¶ï¼š|æœ€æ–° - å‰ä¸€æ—¥| / å‰ä¸€æ—¥ â‰¥ é˜ˆå€¼ï¼ˆå‰ä¸€æ—¥=0ä¸”æœ€æ–°>0 â†’ âˆï¼›å‰ä¸€æ—¥>0ä¸”æœ€æ–°=0 â†’ -100%ï¼‰
    æ–‡æ¡ˆï¼šğŸš¨å¼‚å¸¸æŠ¥è­¦ XX Provideræœ€æ–°ä¸€å¤©æ±‡å…¥é‡å¼‚å¸¸å‡é«˜/å‡å°‘
    show_summary=True æ—¶ï¼Œæ˜¾ç¤ºâ€œæœ€æ–°ä¸€å¤©æ±‡å…¥æ€»ç»“â€ï¼ˆå¿½ç•¥æŒ‡å®š Providerï¼›æ˜ç»†æŒ‰æœ€æ–°æ—¥é™åºï¼‰
    """
    if df_daily.empty or df_daily["date"].isna().all():
        st.warning("æ— å¯ç”¨æ—¥æœŸæ•°æ®")
        return

    dates_sorted = sorted(df_daily["date"].dropna().unique())
    if len(dates_sorted) < 2:
        st.markdown("<div class='alert-box'>æ•°æ®ä¸è¶³ 2 å¤©ï¼Œæ— æ³•è¿›è¡Œä¸å‰ä¸€å¤©çš„æ¯”è¾ƒ</div>", unsafe_allow_html=True)
        return

    latest_date = dates_sorted[-1]
    prev_date = dates_sorted[-2]

    latest_df = (df_daily[df_daily["date"] == latest_date]
                 .groupby(["providerid", "provider_label"], dropna=False)["importcount"]
                 .sum().reset_index().rename(columns={"importcount": "latest_count"}))
    prev_df = (df_daily[df_daily["date"] == prev_date]
               .groupby(["providerid", "provider_label"], dropna=False)["importcount"]
               .sum().reset_index().rename(columns={"importcount": "prev_count"}))

    comp = pd.merge(latest_df, prev_df, on=["providerid", "provider_label"], how="outer").fillna(0)

    normal_candidates = comp["latest_count"] > 500
    drop_to_zero_candidates = (comp["latest_count"] == 0) & (comp["prev_count"] > 0)
    comp_alert = comp[normal_candidates | drop_to_zero_candidates].copy()

    st.markdown(
        f"<div class='alert-box'><b>ğŸš¨ å¼‚å¸¸æŠ¥è­¦ï¼ˆ{title_latest_day}ï¼š{pd.to_datetime(latest_date).strftime('%Y/%m/%d')} å¯¹æ¯” {pd.to_datetime(prev_date).strftime('%Y/%m/%d')}ï¼Œé˜ˆå€¼ {threshold_pct:.1f}%ï¼‰</b></div>",
        unsafe_allow_html=True
    )

    if comp_alert.empty:
        st.markdown("<div class='alert-box'>âœ… æœªå‘ç°å¼‚å¸¸æ³¢åŠ¨ï¼ˆæ»¡è¶³æ¡ä»¶çš„ Providerï¼‰</div>", unsafe_allow_html=True)
    else:
        def calc_ratio(row):
            prev, now = row["prev_count"], row["latest_count"]
            if prev == 0:
                return float("inf") if now > 0 else 0.0
            return (now - prev) / prev

        comp_alert["change_ratio"] = comp_alert.apply(calc_ratio, axis=1)
        comp_alert["direction"] = comp_alert.apply(lambda r: "å‡é«˜" if r["latest_count"] >= r["prev_count"] else "å‡å°‘", axis=1)
        threshold_ratio = float(threshold_pct) / 100.0
        alerts_df = comp_alert[comp_alert["change_ratio"].abs() >= threshold_ratio].copy()

        if alerts_df.empty:
            st.markdown("<div class='alert-box'>âœ… æœªå‘ç°å¼‚å¸¸æ³¢åŠ¨ï¼ˆæ»¡è¶³æ¡ä»¶çš„ Providerï¼‰</div>", unsafe_allow_html=True)
        else:
            # âœ… æŠ¥è­¦åˆ—è¡¨ï¼šæŒ‰â€œå‰ä¸€æ—¥æ±‡å…¥é‡â€ä»é«˜åˆ°ä½è¾“å‡º
            alerts_df_sorted = alerts_df.sort_values(by="prev_count", ascending=False)

            for _, row in alerts_df_sorted.iterrows():
                msg = f"ğŸš¨å¼‚å¸¸æŠ¥è­¦ {row['provider_label']}æœ€æ–°ä¸€å¤©æ±‡å…¥é‡å¼‚å¸¸{row['direction']}"
                st.markdown(f"<div class='alert-line'>{msg}</div>", unsafe_allow_html=True)

            # âœ… æŠ¥è­¦æ˜ç»†ï¼šæŒ‰â€œå‰ä¸€æ—¥æ±‡å…¥é‡â€ä»é«˜åˆ°ä½å±•ç¤ºä¸å¯¼å‡º
            pretty = alerts_df_sorted.rename(columns={
                "providerid": "ProviderId",
                "provider_label": "Provider",
                "latest_count": "æœ€æ–°æ—¥æ±‡å…¥é‡",
                "prev_count": "å‰ä¸€æ—¥æ±‡å…¥é‡",
            }).copy()
            pretty["æœ€æ–°æ—¥æœŸ"] = pd.to_datetime(latest_date).strftime("%Y/%m/%d")
            pretty["å‰ä¸€æ—¥æœŸ"] = pd.to_datetime(prev_date).strftime("%Y/%m/%d")
            pretty["å˜åŒ–æ¯”ä¾‹"] = pretty["change_ratio"].apply(lambda x: "âˆ" if x == float("inf") else f"{(x*100):.2f}%")

            cols = ["ProviderId", "Provider", "å‰ä¸€æ—¥æœŸ", "å‰ä¸€æ—¥æ±‡å…¥é‡", "æœ€æ–°æ—¥æœŸ", "æœ€æ–°æ—¥æ±‡å…¥é‡", "å˜åŒ–æ¯”ä¾‹", "direction"]
            pretty = pretty[cols]
            with st.expander("æŸ¥çœ‹æŠ¥è­¦æ˜ç»†", expanded=False):
                st.dataframe(pretty, use_container_width=True)
                export_excel(pretty, f"{filename_prefix}_æŠ¥è­¦æ˜ç»†_{pd.to_datetime(latest_date).strftime('%Y%m%d')}.xlsx")

    if show_summary:
        full_latest = latest_df.rename(columns={"latest_count": "æœ€æ–°æ—¥æ±‡å…¥é‡"})
        full_prev   = prev_df.rename(columns={"prev_count": "å‰ä¸€æ—¥æ±‡å…¥é‡"})
        full = pd.merge(full_latest, full_prev, on=["providerid", "provider_label"], how="outer").fillna(0)

        if excluded_providers_in_summary:
            full = full[~full["provider_label"].astype(str).str.strip().isin(excluded_providers_in_summary)].copy()

        full["å˜åŒ–é‡"] = full["æœ€æ–°æ—¥æ±‡å…¥é‡"] - full["å‰ä¸€æ—¥æ±‡å…¥é‡"]
        full["æ–¹å‘"]  = full["å˜åŒ–é‡"].apply(lambda x: "å‡é«˜" if x > 0 else ("å‡å°‘" if x < 0 else "æŒå¹³"))

        inc_df = full[full["å˜åŒ–é‡"] > 0]
        dec_df = full[full["å˜åŒ–é‡"] < 0]

        inc_count = int(inc_df.shape[0])
        dec_count = int(dec_df.shape[0])
        inc_total = int(inc_df["å˜åŒ–é‡"].sum()) if not inc_df.empty else 0
        dec_total = int((-dec_df["å˜åŒ–é‡"]).sum()) if not dec_df.empty else 0
        net_change = int(full["å˜åŒ–é‡"].sum())
        net_label = "å‡é«˜" if net_change > 0 else ("å‡å°‘" if net_change < 0 else "æŒå¹³")

        st.markdown("**ğŸ§¾ æœ€æ–°ä¸€å¤©æ±‡å…¥æ€»ç»“ï¼š**")
        st.markdown(f"- å‡é«˜ Provider æ•°ï¼š**{inc_count}**ï¼Œæ€»è®¡å‡é«˜æ•°é‡ï¼š**{inc_total}**")
        st.markdown(f"- é™ä½ Provider æ•°ï¼š**{dec_count}**ï¼Œæ€»è®¡é™ä½æ•°é‡ï¼š**{dec_total}**")
        st.markdown(f"- å‡€å˜åŒ–ï¼š**{net_label} {abs(net_change)}**")

        summary_detail = full.rename(columns={
            "providerid": "ProviderId",
            "provider_label": "Provider",
        }).copy()
        summary_detail["æœ€æ–°æ—¥æœŸ"] = pd.to_datetime(latest_date).strftime("%Y/%m/%d")
        summary_detail["å‰ä¸€æ—¥æœŸ"] = pd.to_datetime(prev_date).strftime("%Y/%m/%d")
        summary_detail = summary_detail.sort_values(by="æœ€æ–°æ—¥æ±‡å…¥é‡", ascending=False)
        summary_detail = summary_detail[["ProviderId", "Provider", "å‰ä¸€æ—¥æœŸ", "å‰ä¸€æ—¥æ±‡å…¥é‡", "æœ€æ–°æ—¥æœŸ", "æœ€æ–°æ—¥æ±‡å…¥é‡", "å˜åŒ–é‡", "æ–¹å‘"]]

        with st.expander("æŸ¥çœ‹æ±‡å…¥æ€»ç»“æ˜ç»†", expanded=False):
            st.dataframe(summary_detail, use_container_width=True)
            export_excel(summary_detail, f"{filename_prefix}_æ±‡å…¥æ€»ç»“æ˜ç»†_{pd.to_datetime(latest_date).strftime('%Y%m%d')}.xlsx")

# =========================
# Provider æ˜ å°„
# =========================
provider_map = pd.DataFrame()
if provider_file:
    try:
        provider_map = pd.read_excel(provider_file)
        provider_map = normalize_columns(provider_map)
        if "providername" not in provider_map.columns or "providerid" not in provider_map.columns:
            st.error("Provider æ˜ å°„éœ€åŒ…å«ï¼šProviderName ä¸ ProviderId")
            st.stop()
        provider_map = provider_map.drop_duplicates(subset=["providerid"]).reset_index(drop=True)
    except Exception as e:
        st.error(f"è¯»å– Provider æ˜ å°„å¤±è´¥ï¼š{e}")
        st.stop()

# =========================
# æ±‡å…¥é‡ä¸èŠ‚å‡æ—¥
# =========================
import_data = prepare_import_data(import_files, provider_map)
holidays_set = load_holidays_set(holidays_file)

# ===== å…¨å±€ç»Ÿè®¡å¿½ç•¥ï¼šNOWNEWS(ç°¡ä¸­) =====
import_data = filter_excluded_providers(import_data, EXCLUDED_PROVIDERS_GLOBAL)

# =========================
# åŠŸèƒ½ 1ï¼šå•æ—¥åˆ†æ
# =========================
if menu == "åŠŸèƒ½ 1ï¼šå•æ—¥åˆ†æ":
    st.markdown("<div class='page-title'>ğŸ—“ï¸ğŸ“Š å•æ—¥åˆ†æ</div>", unsafe_allow_html=True)
    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        dates = sorted(import_data["date_parsed"].dropna().unique())
        if not dates:
            st.warning("æ— æœ‰æ•ˆæ—¥æœŸ")
        else:
            date_strs = [pd.to_datetime(d).strftime("%Y-%m-%d") for d in dates]
            selected_date_str = st.selectbox("é€‰æ‹©æ—¥æœŸ", date_strs)
            selected_date = pd.to_datetime(selected_date_str).date()

            day_data = import_data[import_data["date_parsed"] == selected_date]
            provider_counts = (day_data.groupby("provider_label", dropna=False)["importcount"]
                               .sum().reset_index().sort_values(by="importcount", ascending=False))
            provider_counts = provider_counts.rename(columns={"provider_label": "Provider", "importcount": "æ±‡å…¥æ•°é‡"})

            st.dataframe(provider_counts, use_container_width=True)
            fig = px.bar(provider_counts, x="Provider", y="æ±‡å…¥æ•°é‡", title=f"{selected_date_str} æ±‡å…¥æ•°é‡")
            st.plotly_chart(fig, use_container_width=True)

            export_excel(provider_counts, f"å•æ—¥_æ±‡å…¥_{selected_date_str}.xlsx")

# =========================
# åŠŸèƒ½ 2ï¼šä»…å·¥ä½œæ—¥ï¼ˆæœ€æ–°æ—¥æ’åºåˆ†ç»„ï¼Œæ¯ 10 ä¸ªä¸€ç»„ + æ±‡å…¥æ€»ç»“ï¼‰
# =========================
elif menu == "åŠŸèƒ½ 2ï¼šä»…å·¥ä½œæ—¥":
    st.markdown("<div class='page-title'>ğŸ§‘â€ğŸ’¼ğŸ“ˆ ä»…å·¥ä½œæ—¥</div>", unsafe_allow_html=True)
    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        df = import_data.copy()
        df["weekday"] = pd.to_datetime(df["date_parsed"]).dt.weekday
        df = df[df["weekday"] < 5].copy()

        use_holidays = st.checkbox("æ’é™¤èŠ‚å‡æ—¥", value=True, key="workdays_holiday_toggle")
        if use_holidays:
            if len(holidays_set) > 0:
                df = df[~df["date_parsed"].isin(holidays_set)].copy()
            else:
                st.info("æœªæä¾›èŠ‚å‡æ—¥æ–‡ä»¶")

        # ä»…ä¸­æ–‡ ProviderName
        df = filter_cn_named(df)
        if df.empty:
            st.warning("æ— æ•°æ®")
        else:
            all_providers = sorted(df["provider_label"].dropna().unique().tolist())
            whitelist = st.sidebar.multiselect("Provider ç­›é€‰", options=all_providers, default=[])
            if whitelist:
                df = df[df["provider_label"].isin(whitelist)].copy()

            if df.empty:
                st.warning("æ— æ•°æ®")
            else:
                daily_import = (df.groupby(["providerid", "provider_label", "date_parsed"], dropna=False)["importcount"]
                                .sum().reset_index().rename(columns={"date_parsed": "date"}))
                anomaly_alerts_block_dod_latest_gt500(
                    daily_import, "æœ€æ–°å·¥ä½œæ—¥", "ä»…å·¥ä½œæ—¥", alert_threshold_pct,
                    show_summary=True, excluded_providers_in_summary=EXCLUDED_PROVIDERS_IN_SUMMARY
                )

                # å®Œæ•´æ—¥æœŸï¼ˆä»…å·¥ä½œæ—¥ï¼Œè€ƒè™‘èŠ‚å‡æ—¥å¼€å…³ï¼‰
                min_d, max_d = df["date_parsed"].min(), df["date_parsed"].max()
                date_list = make_date_list(min_d, max_d, policy="workdays", use_holidays=use_holidays, holidays_set=holidays_set)

                providers_list = sorted(df["provider_label"].dropna().unique().tolist())
                trend_complete = build_complete_trend_data(df, date_list, providers_list)

                latest_date = date_list[-1] if len(date_list) > 0 else None
                if latest_date is not None:
                    latest_day_counts = (trend_complete[trend_complete["date"] == latest_date]
                                         .groupby("provider_label", dropna=False)["importcount"]
                                         .sum().sort_values(ascending=False))
                    providers_sorted = latest_day_counts.index.tolist()
                else:
                    providers_sorted = providers_list

                plot_grouped_trends(trend_complete, providers_sorted, date_list, group_size=10, export_name="è¶‹åŠ¿_ä»…å·¥ä½œæ—¥.xlsx")

# =========================
# åŠŸèƒ½ 3ï¼šä»…å‘¨æœ«ï¼ˆæ€»é‡æ’åºåˆ†ç»„ï¼‰
# =========================
elif menu == "åŠŸèƒ½ 3ï¼šä»…å‘¨æœ«":
    st.markdown("<div class='page-title'>ğŸ›ŒğŸ“ˆ ä»…å‘¨æœ«</div>", unsafe_allow_html=True)
    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        df = import_data.copy()
        df["weekday"] = pd.to_datetime(df["date_parsed"]).dt.weekday
        df = df[df["weekday"] >= 5].copy()

        # ä»…ä¸­æ–‡ ProviderName
        df = filter_cn_named(df)
        if df.empty:
            st.warning("æ— æ•°æ®")
        else:
            all_providers = sorted(df["provider_label"].dropna().unique().tolist())
            whitelist = st.sidebar.multiselect("Provider ç­›é€‰", options=all_providers, default=[], key="wl_weekends")
            if whitelist:
                df = df[df["provider_label"].isin(whitelist)].copy()

            if df.empty:
                st.warning("æ— æ•°æ®")
            else:
                daily_import = (df.groupby(["providerid", "provider_label", "date_parsed"], dropna=False)["importcount"]
                                .sum().reset_index().rename(columns={"date_parsed": "date"}))
                anomaly_alerts_block_dod_latest_gt500(daily_import, "æœ€æ–°å‘¨æœ«æ—¥", "ä»…å‘¨æœ«", alert_threshold_pct)

                min_d, max_d = df["date_parsed"].min(), df["date_parsed"].max()
                date_list = make_date_list(min_d, max_d, policy="weekends", use_holidays=False, holidays_set=set())

                providers_list = sorted(df["provider_label"].dropna().unique().tolist())
                trend_complete = build_complete_trend_data(df, date_list, providers_list)

                provider_total = trend_complete.groupby("provider_label", dropna=False)["importcount"].sum().sort_values(ascending=False)
                providers_sorted = provider_total.index.tolist()

                plot_grouped_trends(trend_complete, providers_sorted, date_list, group_size=10, export_name="è¶‹åŠ¿_ä»…å‘¨æœ«.xlsx")

# =========================
# åŠŸèƒ½ 4ï¼šå…¨éƒ¨æ•°æ®ï¼ˆæ€»é‡æ’åºåˆ†ç»„ï¼‰
# =========================
elif menu == "åŠŸèƒ½ 4ï¼šå…¨éƒ¨æ•°æ®":
    st.markdown("<div class='page-title'>ğŸ“šğŸ“ˆ å…¨éƒ¨æ•°æ®</div>", unsafe_allow_html=True)
    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        df = import_data.copy()
        # ä»…ä¸­æ–‡ ProviderName
        df = filter_cn_named(df)
        if df.empty:
            st.warning("æ— æ•°æ®")
        else:
            all_providers = sorted(df["provider_label"].dropna().unique().tolist())
            whitelist = st.sidebar.multiselect("Provider ç­›é€‰", options=all_providers, default=[], key="wl_all")
            if whitelist:
                df = df[df["provider_label"].isin(whitelist)].copy()

            if df.empty:
                st.warning("æ— æ•°æ®")
            else:
                daily_import = (df.groupby(["providerid", "provider_label", "date_parsed"], dropna=False)["importcount"]
                                .sum().reset_index().rename(columns={"date_parsed": "date"}))
                anomaly_alerts_block_dod_latest_gt500(daily_import, "æœ€æ–°ä¸€å¤©", "å…¨éƒ¨æ•°æ®", alert_threshold_pct)

                min_d, max_d = df["date_parsed"].min(), df["date_parsed"].max()
                date_list = make_date_list(min_d, max_d, policy="all", use_holidays=False, holidays_set=set())

                providers_list = sorted(df["provider_label"].dropna().unique().tolist())
                trend_complete = build_complete_trend_data(df, date_list, providers_list)

                provider_total = trend_complete.groupby("provider_label", dropna=False)["importcount"].sum().sort_values(ascending=False)
                providers_sorted = provider_total.index.tolist()

                plot_grouped_trends(trend_complete, providers_sorted, date_list, group_size=10, export_name="è¶‹åŠ¿_å…¨éƒ¨æ•°æ®.xlsx")
