import streamlit as st
import pandas as pd
import plotly.express as px
import os
from io import BytesIO

# =========================
# é¡µé¢é…ç½®ä¸æ ·å¼
# =========================
st.set_page_config(page_title="èµ„è®¯å¹³å°æ•°æ®åˆ†æ", layout="wide")

# æ ‡é¢˜ä¸å„çº§æ ‡é¢˜å­—å·ç¼©å°ï¼ˆçº¦ä¸ºé»˜è®¤çš„ä¸€åŠï¼‰
st.markdown("""
<style>
h1 { font-size: 1.1rem !important; }
h2 { font-size: 0.95rem !important; }
h3 { font-size: 0.85rem !important; }
</style>
""", unsafe_allow_html=True)

st.title("èµ„è®¯å¹³å°æ–‡ç« å®¡æ ¸æ•°æ®åˆ†æ")

# =========================
# èœå•ï¼ˆå››ä¸ªé¡¶çº§åŠŸèƒ½ï¼‰
# =========================
menu = st.sidebar.radio("é€‰æ‹©åŠŸèƒ½", [
    "åŠŸèƒ½ 1ï¼šå•æ—¥åˆ†æ",
    "åŠŸèƒ½ 2ï¼šä»…å·¥ä½œæ—¥",
    "åŠŸèƒ½ 3ï¼šä»…å‘¨æœ«",
    "åŠŸèƒ½ 4ï¼šå…¨éƒ¨æ•°æ®"
])

# =========================
# ä¸Šä¼ æ–‡ä»¶
# =========================
st.sidebar.markdown("æ–‡ä»¶ä¸Šä¼ ")
provider_file = st.sidebar.file_uploader("ä¸Šä¼  Provider æ˜ å°„", type=["xlsx"])
import_files = st.sidebar.file_uploader("ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶", type=["xlsx"], accept_multiple_files=True)
holidays_file = st.sidebar.file_uploader("ä¸Šä¼ èŠ‚å‡æ—¥", type=["csv"])

# =========================
# å…¨å±€å‚æ•°ï¼ˆæŠ¥è­¦é˜ˆå€¼ï¼‰
# =========================
st.sidebar.markdown("å‚æ•°è®¾ç½®")
alert_threshold_pct = st.sidebar.slider("æŠ¥è­¦é˜ˆå€¼", min_value=10, max_value=90, value=50, step=5)

# =========================
# å·¥å…·å‡½æ•°
# =========================
def export_excel(df, filename):
    output = BytesIO()
    writer = None
    for eng in ("openpyxl", "xlsxwriter"):
        try:
            writer = pd.ExcelWriter(output, engine=eng)
            break
        except Exception:
            writer = None
    if writer is None:
        st.error("ç¼ºå°‘ Excel å†™å…¥å¼•æ“ï¼Œè¯·å®‰è£… openpyxl æˆ– XlsxWriter")
        st.stop()
    with writer:
        df.to_excel(writer, index=False, sheet_name='Sheet1')
    st.download_button("ä¸‹è½½ç»“æœ", output.getvalue(), file_name=filename,
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

def normalize_columns(df):
    df.columns = [col.strip().lower() for col in df.columns]
    return df

def parse_date_series(s):
    return pd.to_datetime(s, errors='coerce').dt.date

def load_holidays_set(uploaded_csv) -> set:
    if uploaded_csv is None:
        return set()
    try:
        df = pd.read_csv(uploaded_csv)
        df = normalize_columns(df)
        if "date" not in df.columns:
            st.error("èŠ‚å‡æ—¥æ–‡ä»¶éœ€åŒ…å«åˆ—ï¼šdate")
            return set()
        df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.date
        df = df.dropna(subset=["date"]).reset_index(drop=True)
        return set(df["date"].tolist())
    except Exception as e:
        st.error(f"è¯»å–èŠ‚å‡æ—¥æ–‡ä»¶å¤±è´¥ï¼š{e}")
        return set()

def anomaly_alerts_block(df_daily: pd.DataFrame, title_latest_day: str, filename_prefix: str, threshold_pct: float):
    if df_daily.empty or df_daily["date"].isna().all():
        st.warning("æ— å¯ç”¨æ—¥æœŸæ•°æ®")
        return

    latest_date = df_daily["date"].max()
    latest_df = df_daily[df_daily["date"] == latest_date].copy()
    history_df = df_daily[df_daily["date"] < latest_date].copy()

    st.markdown("""
        <style>
        .alert-exclam { color: #d00000; font-weight: 800; font-size: 16px; margin-right: 6px; }
        .alert-line { font-size: 14px; line-height: 1.6; }
        .alert-box { padding: 8px 10px; background-color: #fff5f5; border-left: 4px solid #d00000; border-radius: 6px; margin-bottom: 12px; }
        </style>
    """, unsafe_allow_html=True)

    if history_df.empty:
        st.markdown(
            f"<div class='alert-box'>ä»…æœ‰{title_latest_day} {pd.to_datetime(latest_date).strftime('%Y/%m/%d')}ï¼Œæ— å†å²å¯¹æ¯”</div>",
            unsafe_allow_html=True
        )
        return

    hist_mean = (
        history_df.groupby(["providerid", "provider_label"], dropna=False)["importcount"]
        .mean().reset_index().rename(columns={"importcount": "hist_avg"})
    )

    compare_df = pd.merge(
        latest_df[["providerid", "provider_label", "date", "importcount"]],
        hist_mean, on=["providerid", "provider_label"], how="left"
    )
    compare_df = compare_df[compare_df["hist_avg"] > 500].copy()

    compare_df["change_ratio"] = (compare_df["importcount"] - compare_df["hist_avg"]) / compare_df["hist_avg"]
    compare_df["direction"] = compare_df["change_ratio"].apply(lambda x: "ä¸Šå‡" if x >= 0 else "é™ä½")
    compare_df["change_pct"] = (compare_df["change_ratio"] * 100).round(2)

    threshold_ratio = float(threshold_pct) / 100.0
    alerts_df = compare_df[compare_df["change_ratio"].abs() >= threshold_ratio].copy()

    if alerts_df.empty:
        st.markdown(
            f"<div class='alert-box'>âœ… {title_latest_day} {pd.to_datetime(latest_date).strftime('%Y/%m/%d')} æœªå‘ç°å¼‚å¸¸</div>",
            unsafe_allow_html=True
        )
    else:
        st.markdown(
            f"<div class='alert-box'><b>ğŸš© å¼‚å¸¸æŠ¥è­¦ï¼ˆé˜ˆå€¼ {threshold_pct}%ï¼‰</b><br/>",
            unsafe_allow_html=True
        )
        for _, row in alerts_df.sort_values(by="change_ratio", key=lambda s: s.abs(), ascending=False).iterrows():
            date_str = pd.to_datetime(row["date"]).strftime("%Y/%m/%d")
            msg = f"<span class='alert-exclam'>ï¼</span><span class='alert-line'>{row['provider_label']} åœ¨ {date_str} çš„æ±‡å…¥é‡å¼‚å¸¸{row['direction']}</span>"
            st.markdown(msg, unsafe_allow_html=True)
        st.markdown("</div>", unsafe_allow_html=True)

        show_cols = ["providerid", "provider_label", "date", "importcount", "hist_avg", "change_pct", "direction"]
        pretty_df = alerts_df[show_cols].copy()
        pretty_df = pretty_df.rename(columns={
            "providerid": "ProviderId",
            "provider_label": "æä¾›æ–¹",
            "date": "æ—¥æœŸ",
            "importcount": "æœ€æ–°æ—¥æ±‡å…¥é‡",
            "hist_avg": "è¿‡å¾€å‡å€¼",
            "change_pct": "å˜åŒ–ç™¾åˆ†æ¯”",
            "direction": "æ–¹å‘"
        })
        pretty_df["æ—¥æœŸ"] = pd.to_datetime(pretty_df["æ—¥æœŸ"]).dt.strftime("%Y/%m/%d")
        with st.expander("æŸ¥çœ‹å¼‚å¸¸æ˜ç»†", expanded=False):
            st.dataframe(pretty_df, use_container_width=True)
            export_excel(pretty_df, f"{filename_prefix}_å¼‚å¸¸_{pd.to_datetime(latest_date).strftime('%Y%m%d')}.xlsx")

def prepare_import_data(import_files, provider_map):
    import_data = pd.DataFrame()
    if import_files:
        for file in import_files:
            df = pd.read_excel(file)
            df = normalize_columns(df)
            date_str = os.path.splitext(file.name)[0]
            df["date"] = date_str
            import_data = pd.concat([import_data, df], ignore_index=True)

    if import_data.empty:
        return import_data

    if "providerid" not in import_data.columns or "importcount" not in import_data.columns:
        st.error("æ±‡å…¥é‡æ–‡ä»¶éœ€åŒ…å«åˆ—ï¼šProviderId ä¸ ImportCount")
        st.stop()

    if not provider_map.empty:
        import_data = import_data.merge(provider_map, on="providerid", how="left")

    import_data["providerid_str"] = import_data["providerid"].astype(str)
    if "providername" in import_data.columns:
        import_data["provider_label"] = import_data["providername"].where(import_data["providername"].notna(),
                                                                        import_data["providerid_str"])
    else:
        import_data["provider_label"] = import_data["providerid_str"]

    import_data["date_parsed"] = parse_date_series(import_data["date"])
    if import_data["date_parsed"].isna().any():
        st.warning("å‘ç°æ— æ•ˆæ—¥æœŸè®°å½•ï¼Œå·²å¿½ç•¥")
        import_data = import_data[~import_data["date_parsed"].isna()].copy()

    return import_data

# =========================
# Provider æ˜ å°„
# =========================
provider_map = pd.DataFrame()
if provider_file:
    try:
        provider_map = pd.read_excel(provider_file)
        provider_map = normalize_columns(provider_map)
        if "providername" not in provider_map.columns or "providerid" not in provider_map.columns:
            st.error("Provider æ˜ å°„éœ€åŒ…å«ï¼šProviderName ä¸ ProviderId")
            st.stop()
        provider_map = provider_map.drop_duplicates(subset=["providerid"]).reset_index(drop=True)
    except Exception as e:
        st.error(f"è¯»å– Provider æ˜ å°„å¤±è´¥ï¼š{e}")
        st.stop()

# =========================
# æ±‡å…¥é‡ä¸èŠ‚å‡æ—¥
# =========================
import_data = prepare_import_data(import_files, provider_map)
holidays_set = load_holidays_set(holidays_file)

# =========================
# åŠŸèƒ½ 1ï¼šå•æ—¥åˆ†æ
# =========================
if menu == "åŠŸèƒ½ 1ï¼šå•æ—¥åˆ†æ":
    st.subheader("å•æ—¥åˆ†æ")
    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        dates = sorted(import_data["date_parsed"].dropna().unique())
        if not dates:
            st.warning("æ— æœ‰æ•ˆæ—¥æœŸ")
        else:
            date_strs = [pd.to_datetime(d).strftime("%Y-%m-%d") for d in dates]
            selected_date_str = st.selectbox("é€‰æ‹©æ—¥æœŸ", date_strs)
            selected_date = pd.to_datetime(selected_date_str).date()

            day_data = import_data[import_data["date_parsed"] == selected_date]
            provider_counts = (day_data.groupby("provider_label", dropna=False)["importcount"]
                               .sum().reset_index().sort_values(by="importcount", ascending=False))
            provider_counts = provider_counts.rename(columns={"provider_label": "æä¾›æ–¹", "importcount": "æ±‡å…¥æ•°é‡"})

            st.dataframe(provider_counts, use_container_width=True)

            fig = px.bar(provider_counts, x="æä¾›æ–¹", y="æ±‡å…¥æ•°é‡",
                         title=f"{selected_date_str} æ±‡å…¥æ•°é‡")
            st.plotly_chart(fig, use_container_width=True)

            export_excel(provider_counts, f"å•æ—¥_æ±‡å…¥_{selected_date_str}.xlsx")

# =========================
# åŠŸèƒ½ 2ï¼šä»…å·¥ä½œæ—¥
# =========================
elif menu == "åŠŸèƒ½ 2ï¼šä»…å·¥ä½œæ—¥":
    st.subheader("ä»…å·¥ä½œæ—¥")
    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        all_providers = sorted(import_data["provider_label"].dropna().unique().tolist())
        whitelist = st.sidebar.multiselect("æä¾›æ–¹ç­›é€‰", options=all_providers, default=[])

        df = import_data.copy()
        if whitelist:
            df = df[df["provider_label"].isin(whitelist)].copy()

        df["weekday"] = pd.to_datetime(df["date_parsed"]).dt.weekday
        df = df[df["weekday"] < 5].copy()

        use_holidays = st.checkbox("æ’é™¤èŠ‚å‡æ—¥", value=True, key="workdays_holiday_toggle")
        if use_holidays:
            if len(holidays_set) > 0:
                df = df[~df["date_parsed"].isin(holidays_set)].copy()
            else:
                st.info("æœªæä¾›èŠ‚å‡æ—¥æ–‡ä»¶")

        if df.empty:
            st.warning("æ— æ•°æ®")
        else:
            daily_import = (df.groupby(["providerid", "provider_label", "date_parsed"], dropna=False)["importcount"]
                            .sum().reset_index().rename(columns={"date_parsed": "date"}))
            anomaly_alerts_block(daily_import, "æœ€æ–°å·¥ä½œæ—¥", "ä»…å·¥ä½œæ—¥", alert_threshold_pct)

            provider_total = df.groupby("provider_label", dropna=False)["importcount"].sum().sort_values(ascending=False)
            providers_sorted = provider_total.index.tolist()
            group_size = 10
            provider_groups = [providers_sorted[i:i+group_size] for i in range(0, len(providers_sorted), group_size)]

            trend_data = (df.groupby(["date_parsed", "provider_label"], dropna=False)["importcount"]
                          .sum().reset_index().rename(columns={"date_parsed": "date"}).sort_values(by="date"))

            all_group_data = []
            for idx, group in enumerate(provider_groups, start=1):
                st.markdown(f"ç¬¬ {idx} ç»„")
                group_data = trend_data[trend_data["provider_label"].isin(group)]
                all_group_data.append(group_data)
                fig = px.line(group_data, x="date", y="importcount", color="provider_label",
                              labels={"provider_label": "æä¾›æ–¹", "importcount": "æ±‡å…¥æ•°é‡", "date": "æ—¥æœŸ"},
                              title="")
                st.plotly_chart(fig, use_container_width=True)
            if all_group_data:
                export_excel(pd.concat(all_group_data), "è¶‹åŠ¿_ä»…å·¥ä½œæ—¥.xlsx")

# =========================
# åŠŸèƒ½ 3ï¼šä»…å‘¨æœ«
# =========================
elif menu == "åŠŸèƒ½ 3ï¼šä»…å‘¨æœ«":
    st.subheader("ä»…å‘¨æœ«")
    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        all_providers = sorted(import_data["provider_label"].dropna().unique().tolist())
        whitelist = st.sidebar.multiselect("æä¾›æ–¹ç­›é€‰", options=all_providers, default=[], key="wl_weekends")

        df = import_data.copy()
        if whitelist:
            df = df[df["provider_label"].isin(whitelist)].copy()

        df["weekday"] = pd.to_datetime(df["date_parsed"]).dt.weekday
        df = df[df["weekday"] >= 5].copy()

        if df.empty:
            st.warning("æ— æ•°æ®")
        else:
            daily_import = (df.groupby(["providerid", "provider_label", "date_parsed"], dropna=False)["importcount"]
                            .sum().reset_index().rename(columns={"date_parsed": "date"}))
            anomaly_alerts_block(daily_import, "æœ€æ–°å‘¨æœ«æ—¥", "ä»…å‘¨æœ«", alert_threshold_pct)

            provider_total = df.groupby("provider_label", dropna=False)["importcount"].sum().sort_values(ascending=False)
            providers_sorted = provider_total.index.tolist()
            group_size = 10
            provider_groups = [providers_sorted[i:i+group_size] for i in range(0, len(providers_sorted), group_size)]

            trend_data = (df.groupby(["date_parsed", "provider_label"], dropna=False)["importcount"]
                          .sum().reset_index().rename(columns={"date_parsed": "date"}).sort_values(by="date"))

            all_group_data = []
            for idx, group in enumerate(provider_groups, start=1):
                st.markdown(f"ç¬¬ {idx} ç»„")
                group_data = trend_data[trend_data["provider_label"].isin(group)]
                all_group_data.append(group_data)
                fig = px.line(group_data, x="date", y="importcount", color="provider_label",
                              labels={"provider_label": "æä¾›æ–¹", "importcount": "æ±‡å…¥æ•°é‡", "date": "æ—¥æœŸ"},
                              title="")
                st.plotly_chart(fig, use_container_width=True)
            if all_group_data:
                export_excel(pd.concat(all_group_data), "è¶‹åŠ¿_ä»…å‘¨æœ«.xlsx")

# =========================
# åŠŸèƒ½ 4ï¼šå…¨éƒ¨æ•°æ®
# =========================
elif menu == "åŠŸèƒ½ 4ï¼šå…¨éƒ¨æ•°æ®":
    st.subheader("å…¨éƒ¨æ•°æ®")
    if import_data.empty:
        st.warning("è¯·ä¸Šä¼ æ±‡å…¥é‡æ–‡ä»¶")
    else:
        all_providers = sorted(import_data["provider_label"].dropna().unique().tolist())
        whitelist = st.sidebar.multiselect("æä¾›æ–¹ç­›é€‰", options=all_providers, default=[], key="wl_all")

        df = import_data.copy()
        if whitelist:
            df = df[df["provider_label"].isin(whitelist)].copy()

        if df.empty:
            st.warning("æ— æ•°æ®")
        else:
            daily_import = (df.groupby(["providerid", "provider_label", "date_parsed"], dropna=False)["importcount"]
                            .sum().reset_index().rename(columns={"date_parsed": "date"}))
            anomaly_alerts_block(daily_import, "æœ€æ–°ä¸€å¤©", "å…¨éƒ¨æ•°æ®", alert_threshold_pct)

            provider_total = df.groupby("provider_label", dropna=False)["importcount"].sum().sort_values(ascending=False)
            providers_sorted = provider_total.index.tolist()
            group_size = 10
            provider_groups = [providers_sorted[i:i+group_size] for i in range(0, len(providers_sorted), group_size)]

            trend_data = (df.groupby(["date_parsed", "provider_label"], dropna=False)["importcount"]
                          .sum().reset_index().rename(columns={"date_parsed": "date"}).sort_values(by="date"))

            all_group_data = []
            for idx, group in enumerate(provider_groups, start=1):
                st.markdown(f"ç¬¬ {idx} ç»„")
                group_data = trend_data[trend_data["provider_label"].isin(group)]
                all_group_data.append(group_data)
                fig = px.line(group_data, x="date", y="importcount", color="provider_label",
                              labels={"provider_label": "æä¾›æ–¹", "importcount": "æ±‡å…¥æ•°é‡", "date": "æ—¥æœŸ"},
                              title="")
                st.plotly_chart(fig, use_container_width=True)
            if all_group_data:
                export_excel(pd.concat(all_group_data), "è¶‹åŠ¿_å…¨éƒ¨æ•°æ®.xlsx")
